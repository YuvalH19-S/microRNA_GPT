{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments, PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_statistics(sequences):\n",
    "    num_sequences = len(sequences)\n",
    "    avg_length = int(sum(len(seq) for seq in sequences) / num_sequences)\n",
    "    min_length = min(len(seq) for seq in sequences)\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "\n",
    "    return {\n",
    "        \"Number of sequences\": num_sequences,\n",
    "        \"Average sequence length\": avg_length,\n",
    "        \"Min sequence length\": min_length,\n",
    "        \"Max sequence length\": max_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Encode RNA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# True if no flanks \n",
    "# if all data - use False\n",
    "hairpin_bool = False\n",
    "if hairpin_bool:\n",
    "    relevant_seq = 'pre_mirna'\n",
    "else:\n",
    "    relevant_seq = 'full_seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# *all data:*\n",
    "\n",
    "gff_data = pd.read_csv('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/Data_output/gff_output/sebastian_db_features_new.csv')\n",
    "mirogen_data = pd.read_csv('/sise/vaksler-group/IsanaRNA/Transformers/Rom/Data_output/miRGeneDB_output/miRGeneDB_features.csv')\n",
    "# # remove the flanks from the sequences:\n",
    "# gff_data = gff_data.dropna(subset=['full_seq', 'flank1', 'flank2']); mirogen_data = mirogen_data.dropna(subset=['full_seq', 'flank1', 'flank2']) # found some null flanks\n",
    "# for index, row in gff_data.iterrows():\n",
    "#     gff_data.at[index, 'full_seq'] = gff_data.at[index, 'full_seq'].replace(row['flank1'], '').replace(row['flank2'], '')\n",
    "# for index, row in mirogen_data.iterrows():\n",
    "#     mirogen_data.at[index, 'full_seq'] = mirogen_data.at[index, 'full_seq'].replace(row['flank1'], '').replace(row['flank2'], '')\n",
    "\n",
    "    \n",
    "# *only train (based on clusters)*:\n",
    "\n",
    "# gff_data = pd.read_csv('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/seq_clusters/gff_train_data.csv')\n",
    "# mirogen_data = pd.read_csv('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/seq_clusters/mirgene_train_data.csv')\n",
    "\n",
    "\n",
    "original_gff_sequences = gff_data[relevant_seq].tolist() ; original_mirogen_sequences  = mirogen_data[relevant_seq].tolist()\n",
    "gff_data = gff_data.dropna(subset=['Star','Mature']); mirogen_data = mirogen_data.dropna(subset=['Star','Mature']) # found some null star and mature\n",
    "\n",
    "\n",
    "def encode_sequence(row):\n",
    "    full_seq = row[relevant_seq]\n",
    "    mature_start = full_seq.find(row['Mature'])\n",
    "    if mature_start == -1:\n",
    "        print(\"no mature\")\n",
    "    mature_end = mature_start + len(row['Mature'])\n",
    "    star_start = full_seq.find(row['Star'])\n",
    "    if star_start == -1:\n",
    "        print(\"no star\")\n",
    "    star_end = star_start + len(row['Star'])\n",
    "    # star_end = len(row['Star'])\n",
    "\n",
    "    encoded_seq = full_seq\n",
    "    if star_start < star_end:\n",
    "        if mature_start < star_start:\n",
    "            encoded_seq = (encoded_seq[:mature_start] + 'ZZZZZ' +\n",
    "                           encoded_seq[mature_start:mature_end] + 'BBBBB' +\n",
    "                           encoded_seq[mature_end:star_start] + 'DDDDD' +\n",
    "                           encoded_seq[star_start:star_end] + 'FFFFF' +\n",
    "                           encoded_seq[star_end:])\n",
    "        else:\n",
    "            encoded_seq = (encoded_seq[:star_start] + 'DDDDD' +\n",
    "                           encoded_seq[star_start:star_end] + 'FFFFF' +\n",
    "                           encoded_seq[star_end:mature_start] + 'ZZZZZ' +\n",
    "                           encoded_seq[mature_start:mature_end] + 'BBBBB' +\n",
    "                           encoded_seq[mature_end:])\n",
    "    return encoded_seq\n",
    "\n",
    "\n",
    "def decode_sequence(encoded_seq):\n",
    "    # decode the encoded patterns with original tokens\n",
    "    decoded_seq = encoded_seq.replace('ZZZZZ', '').replace('BBBBB', '').replace('DDDDD', '').replace('FFFFF', '')\n",
    "    return decoded_seq\n",
    "\n",
    "\n",
    "# Apply the encoding function on both datasets\n",
    "gff_data['encoded_seq'] = gff_data.apply(encode_sequence, axis=1) ; mirogen_data['encoded_seq'] = mirogen_data.apply(encode_sequence, axis=1)\n",
    "\n",
    "# gff_data['encoded_seq'] = gff_data.apply(encode_sequence, axis=1) ; mirogen_data['encoded_seq'] = mirogen_data.apply(encode_sequence, axis=1)\n",
    "gff_data['decoded_seq'] = gff_data['encoded_seq'].apply(decode_sequence) ; mirogen_data['decoded_seq'] = mirogen_data['encoded_seq'].apply(decode_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_full_gff_sequences = gff_data['full_seq'].tolist() ; original_full_mirogen_sequences  = mirogen_data['full_seq'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     174970\n",
      "False      1664\n",
      "Name: count, dtype: int64\n",
      "Index: 26419\n",
      "Mature Start: 31 Mature End: 53\n",
      "Star Start: 27 Star End: 48\n",
      "Encoded Sequence: GTCCCAGAAGAGAACTTGCCAGCTGCCDDDDDACAAACCCGTAGATCCGAACTTFFFFFZZZZZACCCGTAGATCCGAACTTGTGGBBBBBTGACTGGCCGCACAAGCTCGTGTCTATAGGTATGTGTCTGTGTGGCCATCACAGCACCCCTCTC\n",
      "Decoded Sequence: GTCCCAGAAGAGAACTTGCCAGCTGCCACAAACCCGTAGATCCGAACTTACCCGTAGATCCGAACTTGTGGTGACTGGCCGCACAAGCTCGTGTCTATAGGTATGTGTCTGTGTGGCCATCACAGCACCCCTCTC\n",
      "full/hairpin Sequence: GTCCCAGAAGAGAACTTGCCAGCTGCCACAAACCCGTAGATCCGAACTTGTGGTGACTGGCCGCACAAGCTCGTGTCTATAGGTATGTGTCTGTGTGGCCATCACAGCACCCCTCTC\n",
      "len(decoded_seq): 135\n",
      "len(full/hairpin seq): 117\n",
      "------------------------------\n",
      "Index: 98153\n",
      "Mature Start: 31 Mature End: 53\n",
      "Star Start: 35 Star End: 56\n",
      "Encoded Sequence: CGGGGGCCCGGACTCCTGGGTCCTGGCACCCZZZZZACCCGTAGAACCGACCTTGCGGBBBBBDDDDDGTAGAACCGACCTTGCGGGGCCFFFFFTTCGCCGCACACAAGCTCGTGTCTGTGGGTCCGTGTCGGGGGCTCACCATCGCGGCTGGGGCC\n",
      "Decoded Sequence: CGGGGGCCCGGACTCCTGGGTCCTGGCACCCACCCGTAGAACCGACCTTGCGGGTAGAACCGACCTTGCGGGGCCTTCGCCGCACACAAGCTCGTGTCTGTGGGTCCGTGTCGGGGGCTCACCATCGCGGCTGGGGCC\n",
      "full/hairpin Sequence: CGGGGGCCCGGACTCCTGGGTCCTGGCACCCACCCGTAGAACCGACCTTGCGGGGCCTTCGCCGCACACAAGCTCGTGTCTGTGGGTCCGTGTCGGGGGCTCACCATCGCGGCTGGGGCC\n",
      "len(decoded_seq): 138\n",
      "len(full/hairpin seq): 120\n",
      "------------------------------\n",
      "Index: 162160\n",
      "Mature Start: 67 Mature End: 89\n",
      "Star Start: 52 Star End: 74\n",
      "Encoded Sequence: CTGTCATCGTCAACATCATCTATCAGTAGTAGTTGTCACTCGCTCAGTAGACDDDDDATGTTTATCATTCTGTCACTGGGFFFFFZZZZZTCACTGGGATTGTGATGATTGTBBBBBTAGCGAGTGATGCTACAACCTCATAGTTCC\n",
      "Decoded Sequence: CTGTCATCGTCAACATCATCTATCAGTAGTAGTTGTCACTCGCTCAGTAGACATGTTTATCATTCTGTCACTGGGTCACTGGGATTGTGATGATTGTTAGCGAGTGATGCTACAACCTCATAGTTCC\n",
      "full/hairpin Sequence: CTGTCATCGTCAACATCATCTATCAGTAGTAGTTGTCACTCGCTCAGTAGACATGTTTATCATTCTGTCACTGGGATTGTGATGATTGTTAGCGAGTGATGCTACAACCTCATAGTTCC\n",
      "len(decoded_seq): 127\n",
      "len(full/hairpin seq): 119\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print((gff_data[relevant_seq] == gff_data['decoded_seq']).value_counts())\n",
    "# Iterate through the sampled false indices and check each point\n",
    "# get sampled_false_indices (where gff_data['full_seq'] != gff_data['decoded_seq'])\n",
    "false_indices = [idx for idx in gff_data[gff_data[relevant_seq] != gff_data['decoded_seq']].index]\n",
    "sampled_false_indices = np.random.choice(false_indices, 3, replace=False)\n",
    "for idx in sampled_false_indices:\n",
    "    print(\"Index:\", idx)\n",
    "\n",
    "    # Extract necessary information from the DataFrame\n",
    "    row = gff_data.loc[idx]\n",
    "    full_seq = row[relevant_seq]\n",
    "    # full_seq_folding = row['full_seq_folding'] ################################################\n",
    "    encoded_seq = row['encoded_seq']\n",
    "    decoded_seq = row['decoded_seq']\n",
    "\n",
    "    # 1. Check Special Encoding Tokens\n",
    "    # Check if special tokens are correctly replaced during decoding\n",
    "    if 'ZZZZZ' in decoded_seq or 'BBBBB' in decoded_seq or 'DDDDD' in decoded_seq or 'FFFFF' in decoded_seq:\n",
    "        print(\"Special Encoding Tokens not correctly replaced.\")\n",
    "\n",
    "    # # 2. Check Translation Dictionary and Reverse Translation Dictionary\n",
    "    # # Encode and decode the full sequence without adding special tokens and compare with the original\n",
    "    # simple_encoded_seq = ''.join([translation_dict.get(full_seq_folding[i] + full_seq[i], full_seq[i]) for i in range(len(full_seq))])\n",
    "    # simple_decoded_seq = ''.join([reverse_translation_dict.get(char, char) for char in simple_encoded_seq])\n",
    "    # if simple_decoded_seq != full_seq:\n",
    "    #     print(\"Discrepancy in Translation and Reverse Translation Dictionary.\")\n",
    "\n",
    "    # 3. Check Start and End Indices\n",
    "    # Print the start and end indices used during encoding\n",
    "    mature_start = full_seq.find(row['Mature'])\n",
    "    mature_end = mature_start + len(row['Mature'])\n",
    "    star_start = row['Start_star']\n",
    "    star_end = row['End_star']\n",
    "    print(\"Mature Start:\", mature_start, \"Mature End:\", mature_end)\n",
    "    print(\"Star Start:\", star_start, \"Star End:\", star_end)\n",
    "    # Print the Decoded, Encoded, and Full Sequence for comparison\n",
    "    print(\"Encoded Sequence:\", encoded_seq)\n",
    "    print(\"Decoded Sequence:\", decoded_seq)\n",
    "    print(\"full/hairpin Sequence:\", full_seq)\n",
    "    print('len(decoded_seq):', len(decoded_seq))\n",
    "    print('len(full/hairpin seq):', len(full_seq))\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gff_sequences = ['<SOS>' + sequence + '<EOS>' for sequence in gff_data['encoded_seq']]\n",
    "mirgendb_sequences = ['<SOS>' + sequence + '<EOS>' for sequence in mirogen_data['encoded_seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695287350998,
     "user": {
      "displayName": "Yuval Haim",
      "userId": "04274816145412612932"
     },
     "user_tz": -180
    },
    "id": "kQPbAU9RXdEv",
    "outputId": "8009dc07-542a-4fba-a89e-142d69394bca",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of sequences': 176634,\n",
       " 'Average sequence length': 151,\n",
       " 'Min sequence length': 114,\n",
       " 'Max sequence length': 410}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_statistics(gff_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1695287350998,
     "user": {
      "displayName": "Yuval Haim",
      "userId": "04274816145412612932"
     },
     "user_tz": -180
    },
    "id": "kCxZl5h7E9Kc",
    "outputId": "b391b597-2dfb-4842-a2a3-eeeea9819949",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of sequences': 16361,\n",
       " 'Average sequence length': 151,\n",
       " 'Min sequence length': 133,\n",
       " 'Max sequence length': 372}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_statistics(mirgendb_sequences) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFd9bCluodRH",
    "tags": []
   },
   "source": [
    "### 2. Train & Evaluate BPE Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no need to train it here, the train is in colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6j19qdRFodRH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def token_statistics(tokenizer, sequences):\n",
    "    token_lengths = []\n",
    "\n",
    "    for seq in sequences:\n",
    "        tokens = tokenizer.encode(seq).tokens\n",
    "        token_lengths.extend([len(token) for token in tokens])\n",
    "\n",
    "    avg_length = np.mean(token_lengths)\n",
    "    min_length = np.min(token_lengths)\n",
    "    max_length = np.max(token_lengths)\n",
    "    median_length = np.median(token_lengths)\n",
    "    std_dev = np.std(token_lengths)\n",
    "\n",
    "    return {\n",
    "        \"average\": avg_length,\n",
    "        \"min\": min_length,\n",
    "        \"max\": max_length,\n",
    "        \"median\": median_length,\n",
    "        \"std_dev\": std_dev\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_bpe_tokenizer(sequences, vocab_size=10000, min_frequency=3):\n",
    "    special_tokens = [\"<SOS>\", \"<EOS>\", \"ZZZZZ\", \"BBBBB\", \"DDDDD\", \"FFFFF\"]\n",
    "    \n",
    "    # Define BPE model with an unknown token\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"<UNK>\"))\n",
    "    \n",
    "    # Define the BPE trainer with special tokens, vocab size, and min frequency\n",
    "    trainer =  BpeTrainer(special_tokens=special_tokens, max_token_length=6) #vocab_size=vocab_size, min_frequency=min_frequency, \n",
    "    # Train the tokenizer from the iterator of sequences\n",
    "    tokenizer.train_from_iterator(sequences, trainer=trainer)\n",
    "    \n",
    "    # After training, add the special tokens to the tokenizer to ensure they won't be split\n",
    "    tokenizer.add_tokens(special_tokens)\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load tokenizer that was trained in colab\n",
    "bpe_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"GPT_mature_star_bpe_hairpin_tokenizer.json\") # or no flanks: GPT_mature_star_bpe_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokens:\n",
      "2132\n"
     ]
    }
   ],
   "source": [
    "print(\"All tokens:\")\n",
    "unique_tokens=set()\n",
    "vocab = bpe_tokenizer.get_vocab()\n",
    "for token, idx in vocab.items():\n",
    "    unique_tokens.add(token)\n",
    "    if token == \"UNK\":\n",
    "        print(\"<UNK> token found in vocabulary!\")\n",
    "print(len(unique_tokens))\n",
    "unique_tokens_list = sorted(list(unique_tokens), key=lambda x: len(x), reverse=True)\n",
    "# print(unique_tokens_list)\n",
    "file_path = 'unique_tokens.txt'\n",
    "with open(file_path, 'w') as file:\n",
    "    for token in unique_tokens_list:\n",
    "        file.write(token + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcjnV2pXGwQd"
   },
   "source": [
    "### Validate for one-char tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1695282055986,
     "user": {
      "displayName": "Yuval Haim",
      "userId": "04274816145412612932"
     },
     "user_tz": -180
    },
    "id": "6fM1MoFQEUbE",
    "outputId": "4539cc0c-eecc-4764-fc0b-d15721ed94e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-char tokens found: ['n', 'Y', '<', 'F', 'T', 'D', 'a', 'A', 'B', 'R', 'Z', 'W', 'C', 'O', 'N', 't', '>', 'E', 'G', 'g', 'S', 'c']\n"
     ]
    }
   ],
   "source": [
    "one_char_tokens = [token for token in vocab if len(token) == 1]\n",
    "if one_char_tokens:\n",
    "    print(f\"One-char tokens found: {one_char_tokens}\")\n",
    "else:\n",
    "    print(\"No one-char tokens found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zP5FgLgZKgL"
   },
   "source": [
    "### 3. Tokenize datasets (ALL & Human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b38590725cc34dce8ce85af491f2c1ef",
      "1a0b0e423e7e48e190164837e4eb3735",
      "79dcf09d70c5464dbce11c2204ee672c",
      "aa34901ce7014caf9c1f1de5ba1a5ddd",
      "8899ae0fa02046ebba56262c5b420f4f",
      "4c85ce4173424a1f8ac9af09a6b389d4",
      "88fad244f6bd4616a87990cc76e20152",
      "90c7b661d528481c862a2657f7cf7adb",
      "d0e4673db6b2443eacef7ed09f8eec55",
      "32fbe5e0458d47618704b345181dc79b",
      "d3b53538a45741458d0e04f3c19a86bf"
     ]
    },
    "executionInfo": {
     "elapsed": 3785,
     "status": "ok",
     "timestamp": 1695282067809,
     "user": {
      "displayName": "Yuval Haim",
      "userId": "04274816145412612932"
     },
     "user_tz": -180
    },
    "id": "QNjnBtZKUbOR",
    "outputId": "20d50d4d-d720-4b24-9d7e-6a35523ae9ef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = bpe_tokenizer\n",
    "# Define special tokens                            \n",
    "special_tokens = {\n",
    "    \"pad_token\": \"<PAD>\",\n",
    "    \"bos_token\": \"<SOS>\",\n",
    "    \"eos_token\": \"<EOS>\",\n",
    "    \"unk_token\": \"<UNK>\"\n",
    "}\n",
    "\n",
    "# Add special tokens to the tokenizer\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "MAX_SEQ_LEN = max([len(s) for s in gff_sequences]) \n",
    "\n",
    "def tokenize_function(data):\n",
    "    # Tokenize the sequences\n",
    "    output = tokenizer(data[\"sequences\"], truncation=True, padding='max_length', max_length=MAX_SEQ_LEN)\n",
    "    # Use input_ids as labels\n",
    "    output[\"labels\"] = output[\"input_ids\"].copy()\n",
    "    return output\n",
    "\n",
    "dataset = Dataset.from_dict({\"sequences\": gff_sequences})\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "722bfadc7fa54ff69dedd81015f9309e",
      "fe814afe1e1048d1b7784327410f3173",
      "9ce0f5979e204066ba2c0a4dad1ecc25",
      "92c756f58c5e4cf6ba9ae45e25f326d4",
      "00164eb73a2b4a2ca11ee205d765e9ec",
      "570860e27ecc4a9cba73b49486ffdd88",
      "d08b80b1728d420f95531a043ee0a496",
      "a7f375fb7c8b42bfa83fb6513be09619",
      "bde3c653b5c446208c85e12457f2cdd9",
      "a41bf718bf054217916ba4b7c939a171",
      "ac4a0577e774457bb65a1f4c16eafa36"
     ]
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1695282067810,
     "user": {
      "displayName": "Yuval Haim",
      "userId": "04274816145412612932"
     },
     "user_tz": -180
    },
    "id": "nAML_0iGZIq5",
    "outputId": "5181bdb6-e42e-4069-c09e-db84816a1688",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = max([len(s) for s in mirgendb_sequences])\n",
    "mirgendb_datset = Dataset.from_dict({\"sequences\": mirgendb_sequences})\n",
    "tokenized_mirgendb_datasets = mirgendb_datset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNr85koea4lC"
   },
   "source": [
    "### 4. First training on GFF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the GPT-2 model\n",
    "\n",
    "# Create a new GPT-2 configuration and model\n",
    "config = GPT2Config(\n",
    "    vocab_size=len(tokenizer),\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"results_ms/checkpoint-84500\")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "\n",
    "# Define training arguments and train\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_ms_all_data', # with flanks : \"results_ms\"\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_dir='./logs_ms_all_data',  # with flanks : \"logs_ms\"\n",
    "    learning_rate=5e-5\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the pretrain model and tokenizer\n",
    "model.save_pretrained(\"gff_ms_all_data\")  # or no flanks: gff_ms_hairpin_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "executionInfo": {
     "elapsed": 1752663,
     "status": "ok",
     "timestamp": 1695231608769,
     "user": {
      "displayName": "Yuval Haim",
      "userId": "04274816145412612932"
     },
     "user_tz": -180
    },
    "id": "zIcieLRZ7EjR",
    "outputId": "1daa88d8-cd41-4b39-c213-df6bffe70b67",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30690' max='30690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30690/30690 2:00:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.470500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.419300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.411300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.402200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.391400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.384600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.372600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.367300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.362300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.354800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.346900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.341600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.331300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.324700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.298900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.264500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.252700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.251700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.229000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.209100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.209100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.206700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.189700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.171400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.171900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.159500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Define the GPT-2 model\n",
    "# from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "# # Create a new GPT-2 configuration and model\n",
    "# config = GPT2Config(\n",
    "#     vocab_size=len(tokenizer),\n",
    "#     bos_token_id=tokenizer.bos_token_id,\n",
    "#     eos_token_id=tokenizer.eos_token_id\n",
    "# )\n",
    "# model = GPT2LMHeadModel(config)\n",
    "\n",
    "# # Define training arguments and train\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./GPT_mature_star_mirgendb',\n",
    "#     num_train_epochs=15,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     logging_dir='./logs',\n",
    "#     learning_rate=5e-5\n",
    "# )\n",
    "# # mirgendb\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_mirgendb_datasets,\n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "# # Save the pretrain model and tokenizer\n",
    "# model.save_pretrained(\"after_prepocess_mirgendb\")\n",
    "# bpe_tokenizer.save(\"GPT_mature_star_bpe_tokenizer2.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uloOLLzXbA6n"
   },
   "source": [
    "### 4. Standard Fine-tuning with Second Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "executionInfo": {
     "elapsed": 67373,
     "status": "ok",
     "timestamp": 1695231676141,
     "user": {
      "displayName": "Yuval Haim",
      "userId": "04274816145412612932"
     },
     "user_tz": -180
    },
    "id": "k0MD7nVhbQwr",
    "outputId": "ddf6d307-cae8-4138-9490-5f25be5c20a9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14308' max='14308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14308/14308 55:09, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.155900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.131100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.120200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pre-trained model for fine-tuning\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gff_ms_hairpin_all_data\")   # withflanks: gff_ms_all_data / gff_ms\n",
    "\n",
    "# Define fine-tuning arguments with a smaller learning rate\n",
    "fine_tuning_args = TrainingArguments(\n",
    "    output_dir='./mirgene_ms_hairpin_all_data_results',  # with flanks : mirgene_ms_all_data_results / mirgene_ms_results\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_dir='./fine_tuned_mirgene_ms_hairpin_all_data_logs',    # with flanks : fine_tuned_mirgene_ms_all_data_logs / fine_tuned_mirgene_ms_logs\n",
    "    learning_rate=1e-5,  # smaller learning rate for fine-tuning\n",
    ")\n",
    "\n",
    "# Create a trainer instance for fine-tuning\n",
    "fine_tuning_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=fine_tuning_args,\n",
    "    train_dataset=tokenized_mirgendb_datasets,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tuning_trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"mirgene_ms_all_data_hairpin\")    # with flanks : mirgene_ms_all_data / mirgene_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LDcCtdIqycM"
   },
   "source": [
    "### 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19758,
     "status": "ok",
     "timestamp": 1695291215383,
     "user": {
      "displayName": "Yuval Haim",
      "userId": "04274816145412612932"
     },
     "user_tz": -180
    },
    "id": "qZ6caKTnrmez",
    "outputId": "8d7b2689-a776-4e4d-f7c1-6dc8b051aad7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(2134, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=2134, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"mirgene_ms_all_data_hairpin\")  # with flanks : \"gpt_rna_fine_tuned_ms\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 202135.13it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('genreated_500_ms_mirgen_gff_after_preprocess.txt', 'w') as f:\n",
    "    for string in tqdm(generated_sequences):\n",
    "        string = string.replace('<SOS>','').replace('<EOS>','')\n",
    "        f.write(string + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_sequences = []\n",
    "with open('genreated_500_ms_mirgen_gff_after_preprocess.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        # Add each line to the list after stripping newline characters\n",
    "        generated_sequences.append(line.strip())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GPT_ron",
   "language": "python",
   "name": "gpt_ron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00164eb73a2b4a2ca11ee205d765e9ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a0b0e423e7e48e190164837e4eb3735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c85ce4173424a1f8ac9af09a6b389d4",
      "placeholder": "​",
      "style": "IPY_MODEL_88fad244f6bd4616a87990cc76e20152",
      "value": "Map: 100%"
     }
    },
    "32fbe5e0458d47618704b345181dc79b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c85ce4173424a1f8ac9af09a6b389d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "570860e27ecc4a9cba73b49486ffdd88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "722bfadc7fa54ff69dedd81015f9309e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe814afe1e1048d1b7784327410f3173",
       "IPY_MODEL_9ce0f5979e204066ba2c0a4dad1ecc25",
       "IPY_MODEL_92c756f58c5e4cf6ba9ae45e25f326d4"
      ],
      "layout": "IPY_MODEL_00164eb73a2b4a2ca11ee205d765e9ec"
     }
    },
    "79dcf09d70c5464dbce11c2204ee672c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90c7b661d528481c862a2657f7cf7adb",
      "max": 16621,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0e4673db6b2443eacef7ed09f8eec55",
      "value": 16621
     }
    },
    "8899ae0fa02046ebba56262c5b420f4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88fad244f6bd4616a87990cc76e20152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90c7b661d528481c862a2657f7cf7adb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92c756f58c5e4cf6ba9ae45e25f326d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a41bf718bf054217916ba4b7c939a171",
      "placeholder": "​",
      "style": "IPY_MODEL_ac4a0577e774457bb65a1f4c16eafa36",
      "value": " 567/567 [00:00&lt;00:00, 4287.84 examples/s]"
     }
    },
    "9ce0f5979e204066ba2c0a4dad1ecc25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7f375fb7c8b42bfa83fb6513be09619",
      "max": 567,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bde3c653b5c446208c85e12457f2cdd9",
      "value": 567
     }
    },
    "a41bf718bf054217916ba4b7c939a171": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7f375fb7c8b42bfa83fb6513be09619": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa34901ce7014caf9c1f1de5ba1a5ddd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32fbe5e0458d47618704b345181dc79b",
      "placeholder": "​",
      "style": "IPY_MODEL_d3b53538a45741458d0e04f3c19a86bf",
      "value": " 16621/16621 [00:03&lt;00:00, 5165.78 examples/s]"
     }
    },
    "ac4a0577e774457bb65a1f4c16eafa36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b38590725cc34dce8ce85af491f2c1ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a0b0e423e7e48e190164837e4eb3735",
       "IPY_MODEL_79dcf09d70c5464dbce11c2204ee672c",
       "IPY_MODEL_aa34901ce7014caf9c1f1de5ba1a5ddd"
      ],
      "layout": "IPY_MODEL_8899ae0fa02046ebba56262c5b420f4f"
     }
    },
    "bde3c653b5c446208c85e12457f2cdd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d08b80b1728d420f95531a043ee0a496": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0e4673db6b2443eacef7ed09f8eec55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3b53538a45741458d0e04f3c19a86bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe814afe1e1048d1b7784327410f3173": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_570860e27ecc4a9cba73b49486ffdd88",
      "placeholder": "​",
      "style": "IPY_MODEL_d08b80b1728d420f95531a043ee0a496",
      "value": "Map: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
