{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cceba468-c5b4-42d3-81f8-503fae214ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronfay/.conda/envs/GPT_ron/lib/python3.10/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import nt_search\n",
    "from gpt_utils import *\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import os\n",
    "rna_fold_path = os.path.expanduser('~/.conda/envs/myenv/bin/RNAfold')\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.dirname(rna_fold_path)\n",
    "import pandas as pd\n",
    "import json\n",
    "import subprocess\n",
    "import RNA\n",
    "from collections import Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962ce4a-9acb-4f0e-a55f-0c870b11571d",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef073361-0bb7-4242-9157-1f68c7c35ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ct_data(sequence, structure, output_file):\n",
    "    ct_data = {}\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(f\"{len(sequence)} ENERGY\\n\")\n",
    "        stack = []\n",
    "        \n",
    "        for i, (nt, struct) in enumerate(zip(sequence, structure), start=1):\n",
    "            prev_nt = i - 1 if i != 1 else 0\n",
    "            next_nt = i + 1 if i != len(sequence) else 0\n",
    "            \n",
    "            if struct == '(':\n",
    "                stack.append(i)\n",
    "                ct_data[i] = [i, nt, prev_nt, next_nt, 0, i]  # Temporarily set as unpaired\n",
    "            elif struct == ')':\n",
    "                partner = stack.pop()\n",
    "                f.write(f\"{i} {nt} {prev_nt} {next_nt} {partner} {i}\\n\")\n",
    "                ct_data[i] = [i, nt, prev_nt, next_nt, partner, i]\n",
    "                ct_data[partner][4] = i  # Update partner's pairing information\n",
    "            else:\n",
    "                f.write(f\"{i} {nt} {prev_nt} {next_nt} 0 {i}\\n\")\n",
    "                ct_data[i] = [i, nt, prev_nt, next_nt, 0, i]\n",
    "\n",
    "    return ct_data\n",
    "\n",
    "def dotbracket_to_ct(sequence, structure):\n",
    "    # Initialize the list for CT data\n",
    "    ct_data = []\n",
    "    \n",
    "    # Get the pair table from the dot-bracket structure\n",
    "    # The pair table is 1-indexed and the first element is the length of the RNA\n",
    "    pair_table = RNA.ptable(structure)\n",
    "    # Loop through each nucleotide in the sequence\n",
    "    for i, nt in enumerate(sequence, start=1):\n",
    "        # Get the pairing partner from the pair table\n",
    "        partner = pair_table[i]\n",
    "        \n",
    "        # Write the CT data: index, nt, prev, next, partner, index\n",
    "        prev_nt = i - 1 if i > 1 else 0\n",
    "        next_nt = i + 1 if i < len(sequence) else 0\n",
    "        \n",
    "        # Append the data as a tuple or a list\n",
    "        ct_data.append((i, nt, prev_nt, next_nt, partner, i))\n",
    "    \n",
    "    return ct_data\n",
    "\n",
    "                \n",
    "def decode_structure(encoded_seq):\n",
    "    # Reverse the translation_dict to map encoded chars back to their original pairs\n",
    "    reverse_translation_struct = {v: k[0] for k, v in translation_dict.items()}\n",
    "\n",
    "    decoded_structure = ''\n",
    "\n",
    "    i = 0\n",
    "    while i < len(encoded_seq):\n",
    "        # Check for special tokens and treat them separately\n",
    "        if encoded_seq[i:i+5] in {'ZZZZZ', 'BBBBB', 'DDDDD', 'FFFFF'}:\n",
    "            decoded_structure += encoded_seq[i:i+5]\n",
    "            i += 5\n",
    "        elif encoded_seq[i] in reverse_translation_struct:\n",
    "            decoded_structure += reverse_translation_struct[encoded_seq[i]]\n",
    "            i += 1\n",
    "        else:\n",
    "            decoded_structure += '.'\n",
    "            i += 1\n",
    "\n",
    "    return decoded_structure\n",
    "\n",
    "def is_valid_dot_bracket(structure, sequence):\n",
    "    stack = []\n",
    "    valid_pairs = [('U', 'G'), ('G', 'U'), ('C', 'G'), ('G', 'C'), ('A', 'U'), ('U', 'A')]\n",
    "    invalid_pairs_dict = {}\n",
    "    \n",
    "    for i, char in enumerate(structure):\n",
    "        if char == '(':\n",
    "            stack.append((i, sequence[i]))\n",
    "        elif char == ')':\n",
    "            if not stack:\n",
    "                return False, invalid_pairs_dict\n",
    "            else:\n",
    "                position, nucleotide = stack.pop()\n",
    "                if (nucleotide, sequence[i]) not in valid_pairs:\n",
    "                    invalid_pair = f\"{nucleotide}{sequence[i]}\"\n",
    "                    invalid_pairs_dict[invalid_pair] = invalid_pairs_dict.get(invalid_pair, 0) + 1\n",
    "                    \n",
    "    # Check if there are any unmatched parentheses left\n",
    "    if stack:\n",
    "        return False, invalid_pairs_dict\n",
    "    \n",
    "    # Check if any invalid pairs were found\n",
    "    if invalid_pairs_dict:\n",
    "        return False, invalid_pairs_dict\n",
    "        \n",
    "    return True, invalid_pairs_dict\n",
    "\n",
    "\n",
    "def calculate_novelty(gen_seq, real_sequences):\n",
    "    local_scores = [(pairwise2.align.localxx(gen_seq, real_seq, score_only=True), real_seq) for real_seq in real_sequences]\n",
    "    max_score, max_real_seq = max(local_scores, key=lambda x: x[0])\n",
    "    normalized_max_score = max_score / min(len(gen_seq), len(max_real_seq))\n",
    "    avg_score = sum(score for score, _ in local_scores) / len(real_sequences)\n",
    "    return (round(avg_score, 2), round(normalized_max_score, 2))\n",
    "\n",
    "def calculate_local_alignment(sequence1, sequence2):\n",
    "    alignments = pairwise2.align.localxx(sequence1, sequence2)\n",
    "    return alignments[0][2]\n",
    "\n",
    "def calculate_diversity(gen_seq, gen_sequences):\n",
    "    local_scores = [(pairwise2.align.localxx(gen_seq, gen1_seq, score_only=True), gen1_seq) for gen1_seq in gen_sequences if gen_seq != gen1_seq]\n",
    "    max_score, max_real_seq = max(local_scores, key=lambda x: x[0])\n",
    "    normalized_max_score = max_score / min(len(gen_seq), len(max_real_seq))\n",
    "    avg_score = sum(score for score, _ in local_scores) / len(gen_sequences)\n",
    "    return (round(avg_score, 2), round(normalized_max_score, 2))\n",
    "\n",
    "# Helper function to count connections (in mature or star)\n",
    "def count_connections(start, end, ct_data):\n",
    "    connections = 0\n",
    "    for i in range(start, end + 1):\n",
    "        if ct_data[i][4] != 0 and not (start <= ct_data[i][4] <= end): \n",
    "            connections += 1\n",
    "    return connections\n",
    "\n",
    "# Helper function to count connections (in mature or star)\n",
    "def count_connections_both(start_mature, start_star, end_mature, end_star, ct_data):\n",
    "    connections = 0\n",
    "    for i in range(start_mature, end_mature + 1):\n",
    "        if ct_data[i][4] != 0 and (start_mature <= ct_data[i][0] <= end_mature) and (start_star <= ct_data[i][4] <= end_star): ## TODO: change the range of checking ct_data[i][4] ##\n",
    "            connections += 1\n",
    "    return connections\n",
    "\n",
    "def calculate_max_bulge(mature_range, star_range, ct_data):\n",
    "    max_bulge_mature = 0\n",
    "    max_bulge_star = 0\n",
    "    current_bulge = 0\n",
    "    in_bulge = False\n",
    "    bulge_start = -1\n",
    "    bulge_end = -1\n",
    "    mature_bulges = []\n",
    "    star_bulges = []\n",
    "\n",
    "    for i in range(1, len(ct_data)):\n",
    "        if ct_data[i][4] == 0:  # If current position is unpaired\n",
    "            if not in_bulge:\n",
    "                bulge_start = i-1  # Start of the bulge\n",
    "                # print(i,bulge_start)\n",
    "                in_bulge = True\n",
    "            current_bulge += 1\n",
    "            # print(ct_data[i+1] , ct_data[i+1][4])\n",
    "            if i == len(ct_data)-1 or ct_data[i+1][4] != 0:  # If it's the last position or next is paired\n",
    "                bulge_end = i+1  # End of the bulge\n",
    "                # print(i,bulge_end)\n",
    "                # Check if the bulge is completely contained within the mature range\n",
    "                if bulge_start >= mature_range[0] and bulge_end <= mature_range[1]:\n",
    "                    # print(f\"Mature Bulge found from index {bulge_start} to {bulge_end}. Size: {current_bulge}\")\n",
    "                    mature_bulges.append((bulge_start, bulge_end))\n",
    "                    max_bulge_mature = max(max_bulge_mature, current_bulge)\n",
    "                # Check if the bulge is completely contained within the star range\n",
    "                elif bulge_start >= star_range[0] and bulge_end <= star_range[1]:\n",
    "                    # print(f\"Star Bulge found from index {bulge_start} to {bulge_end}. Size: {current_bulge}\")\n",
    "                    star_bulges.append((bulge_start, bulge_end))\n",
    "                    max_bulge_star = max(max_bulge_star, current_bulge)\n",
    "                current_bulge = 0\n",
    "                in_bulge = False\n",
    "        else:\n",
    "            current_bulge = 0\n",
    "            in_bulge = False\n",
    "\n",
    "    return {\n",
    "        \"mature_max_bulge\": max_bulge_mature,\n",
    "        \"star_max_bulge\": max_bulge_star,\n",
    "        \"mature_bulges\": mature_bulges,\n",
    "        \"star_bulges\": star_bulges\n",
    "    }\n",
    "\n",
    "\n",
    "def debug_print(debug, *args):\n",
    "    if debug:\n",
    "        print(*args)\n",
    "\n",
    "def check_seed_family(seed):\n",
    "    # Load seed families from CSV\n",
    "\n",
    "    filename = os.path.abspath(\"/sise/vaksler-group/IsanaRNA/Transformers/Rom/Data_source/seed_family_from_mirgendb.csv\")\n",
    "\n",
    "    # Read CSV using pandas\n",
    "    df = pd.read_csv(filename, encoding='ISO-8859-1')\n",
    "\n",
    "    # Create a dictionary from the 'Seed' and 'Family' columns\n",
    "    seed_family_dict = df.set_index('Seed')['Family'].to_dict()\n",
    "    \n",
    "    return seed_family_dict.get(seed, \"Unknown\")\n",
    "\n",
    "# Helper function to calculate UG & UGUG\n",
    "def find_ug_sequences(decoded_seq, mature_start, mature_end, threshold=3):\n",
    "    # Calculate the search ranges considering the threshold\n",
    "    ug_search_start = max(mature_end - 14 - threshold, 0)\n",
    "    ug_search_end = min(mature_start + threshold, len(decoded_seq))\n",
    "    \n",
    "    ugug_search_start = max(mature_end + 1 - threshold, 0)\n",
    "    ugug_search_end = min(mature_end + 3 + threshold, len(decoded_seq))\n",
    "    \n",
    "    # Search for 'UG' and 'UGUG' sequences in the calculated ranges\n",
    "    ug_index = decoded_seq.find('UG', ug_search_start, ug_search_end) + 1  # +1 to make it 1-indexed\n",
    "    ug = ug_index if ug_index != 0 else \"FALSE\"\n",
    "    \n",
    "    ugug_index = decoded_seq.find('UGUG', ugug_search_start, ugug_search_end) + 1  # +1 to make it 1-indexed\n",
    "    ugug = ugug_index if ugug_index != 0 else \"FALSE\"\n",
    "    \n",
    "    return ug, ugug\n",
    "\n",
    "# Helper function to mer features (for sizes 1 or 2)\n",
    "def calculate_mer_ratios(sequence, mer_size):\n",
    "    total_length = len(sequence)\n",
    "    # If mer_size is greater than the sequence length, return an error or handle appropriately\n",
    "    if mer_size > total_length:\n",
    "        return \"(0.00 .. 0.00)\"\n",
    "    \n",
    "    # Generate all possible combinations of nucleotides of length mer_size\n",
    "    possible_mers = [''.join(p) for p in itertools.product('AUCG', repeat=mer_size)]\n",
    "    mer_counts = Counter([sequence[i:i+mer_size] for i in range(total_length - mer_size + 1)])\n",
    "    \n",
    "    # Calculate ratios\n",
    "    mer_ratios = {mer: mer_counts[mer] / total_length for mer in possible_mers}\n",
    "    max_ratio = max(mer_ratios.values(), default=0)\n",
    "    min_ratio = min(mer_ratios.values(), default=0)\n",
    "    \n",
    "    return f\"({min_ratio:.2f} .. {max_ratio:.2f})\"\n",
    "\n",
    "def calculate_energy(sequence):\n",
    "    # Calculate the secondary structure and the free energy of the structure\n",
    "    structure, energy = RNA.fold(sequence)\n",
    "    \n",
    "    return energy\n",
    "\n",
    "def is_valid_dot_bracket(structure, sequence):\n",
    "    stack = []\n",
    "    valid_pairs = [('U', 'G'), ('G', 'U'), ('C', 'G'), ('G', 'C'), ('A', 'U'), ('U', 'A')]\n",
    "    invalid_pairs_dict = {}\n",
    "    \n",
    "    for i, char in enumerate(structure):\n",
    "        if char == '(':\n",
    "            stack.append((i, sequence[i]))\n",
    "        elif char == ')':\n",
    "            if not stack:\n",
    "                return False, invalid_pairs_dict\n",
    "            else:\n",
    "                position, nucleotide = stack.pop()\n",
    "                if (nucleotide, sequence[i]) not in valid_pairs:\n",
    "                    invalid_pair = f\"{nucleotide}{sequence[i]}\"\n",
    "                    invalid_pairs_dict[invalid_pair] = invalid_pairs_dict.get(invalid_pair, 0) + 1\n",
    "                    \n",
    "    # Check if there are any unmatched parentheses left\n",
    "    if stack:\n",
    "        return False, invalid_pairs_dict\n",
    "    \n",
    "    # Check if any invalid pairs were found\n",
    "    if invalid_pairs_dict:\n",
    "        return False, invalid_pairs_dict\n",
    "        \n",
    "    return True, invalid_pairs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c5cb48-87ab-4742-9bf7-b8dcfb00b75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_rnafold(rna_sequence):\n",
    "    # Start the RNAfold process\n",
    "    process = subprocess.Popen(['RNAfold'],\n",
    "                               stdin=subprocess.PIPE,\n",
    "                               stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE,\n",
    "                               text=True)\n",
    "\n",
    "    # Send the RNA sequence and get the output\n",
    "    output, error = process.communicate(rna_sequence)\n",
    "\n",
    "    # Check for errors\n",
    "    if error:\n",
    "        print(\"Error:\", error)\n",
    "    else:\n",
    "        return output\n",
    "\n",
    "def retrieve_parts_only_nts(encoded_seq):\n",
    "\n",
    "    # Identify positions of special tokens\n",
    "    mature_start = encoded_seq.find('ZZZZZ')\n",
    "    end_mature_indices = encoded_seq[mature_start + 5:].find('BBBBB')\n",
    "    mature_end = mature_start + 5 + end_mature_indices\n",
    "\n",
    "    star_start = encoded_seq.find('DDDDD')\n",
    "    end_star_indices = encoded_seq[star_start + 5:].find('FFFFF')\n",
    "    star_end = star_start + 5 + end_star_indices\n",
    "    \n",
    "    # Decode mature and star parts\n",
    "    decoded_mature = encoded_seq[mature_start + 5:mature_end].replace('T', 'U')\n",
    "    decoded_star = encoded_seq[star_start + 5:star_end].replace('T', 'U')\n",
    "    \n",
    "    decoded_mature = decoded_mature.replace('ZZZZZ', '').replace('BBBBB', '').replace('DDDDD', '').replace('FFFFF', '')\n",
    "    decoded_star = decoded_star.replace('ZZZZZ', '').replace('BBBBB', '').replace('DDDDD', '').replace('FFFFF', '')\n",
    "    \n",
    "    intermediate_seq = encoded_seq.replace('ZZZZZ', '').replace('BBBBB', '').replace('DDDDD', '').replace('FFFFF', '')\n",
    "\n",
    "    # Check for -1 in the find results\n",
    "    if mature_start == -1 or end_mature_indices == -1 or star_start == -1 or end_star_indices == -1:\n",
    "        return None\n",
    "\n",
    "    # Decode full sequence and folding\n",
    "    full_seq_folding = run_rnafold(intermediate_seq)\n",
    "    if full_seq_folding:\n",
    "        # print(full_seq_folding) \n",
    "        full_seq_folding = full_seq_folding.split('\\n')[-2][:-9] # extract nesscery structre from rnafold output\n",
    "        # print(len(full_seq_folding), len(intermediate_seq)) \n",
    "    else:\n",
    "        return -1\n",
    "    full_seq = intermediate_seq.replace('T', 'U')\n",
    "\n",
    "\n",
    "    return {\n",
    "        'encoded_seq': encoded_seq,\n",
    "        'decoded_seq': full_seq,\n",
    "        'mature': decoded_mature,\n",
    "        'star': decoded_star,\n",
    "        'full_seq_folding': full_seq_folding\n",
    "    }\n",
    "\n",
    "\n",
    "def adjust_index(index):\n",
    "    return index + 1\n",
    "\n",
    "def extract_features_only_nts(decoded_seq, full_seq_folding, mature, star):\n",
    "    # Save CT file\n",
    "    if is_valid_dot_bracket(full_seq_folding,decoded_seq):\n",
    "        ct_data = get_ct_data(decoded_seq, full_seq_folding, \"output.ct\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Locate mature and star sequences within the full sequence\n",
    "    mature_start = decoded_seq.find(mature)\n",
    "    mature_end = mature_start + len(mature) - 1  # Adjust to 0-based indexing\n",
    "    star_start = decoded_seq.find(star)\n",
    "    star_end = star_start + len(star) - 1  # Adjust to 0-based indexing\n",
    "    if mature_start < 0 or star_start < 0:\n",
    "        print('mature ot start invalid')\n",
    "        return None\n",
    "\n",
    "    if mature_start < star_start:\n",
    "        loop = decoded_seq[mature_end+1:star_start]\n",
    "        flank1 = decoded_seq[:mature_start]\n",
    "        flank2 = decoded_seq[star_end+1:]\n",
    "        direction = '5p'\n",
    "    else:\n",
    "        loop = decoded_seq[star_end+1:mature_start]\n",
    "        flank1 = decoded_seq[:star_start]\n",
    "        flank2 = decoded_seq[mature_end+1:]\n",
    "        direction = '3p'\n",
    "\n",
    "    # Compute the seed section\n",
    "    seed_start = mature_start + 2  # 2nd nucleotide, 0-indexed\n",
    "    seed_end = seed_start + 7  # 7th nucleotide, 0-indexed\n",
    "    seed = decoded_seq[seed_start-1:seed_end-1]  \n",
    "    seed_family = check_seed_family(seed) # loading dict from shared folder \n",
    "\n",
    "    # Calculate the indices for Loop, flank1, and flank2\n",
    "    loop_start_index = decoded_seq.find(loop) + 1\n",
    "    loop_end_index = loop_start_index + len(loop) - 1\n",
    "\n",
    "    flank1_start_index = decoded_seq.find(flank1) + 1\n",
    "    flank1_end_index = flank1_start_index + len(flank1) - 1\n",
    "\n",
    "    flank2_start_index = decoded_seq.find(flank2) + 1\n",
    "    flank2_end_index = flank2_start_index + len(flank2) - 1\n",
    "    \n",
    "    mature_range, star_range = (adjust_index(mature_start), adjust_index(mature_end)), (adjust_index(star_start), adjust_index(star_end))\n",
    "    \n",
    "    # Feature calculations\n",
    "    # print(mature_start, mature_end , len(ct_data))\n",
    "    mature_connections = count_connections(adjust_index(mature_start), adjust_index(mature_end), ct_data)\n",
    "    \n",
    "    mature_star_connections = count_connections_both(adjust_index(mature_start), adjust_index(star_start), adjust_index(mature_end), adjust_index(star_end), ct_data)\n",
    "\n",
    "    mature_bp_ratio = mature_connections / len(mature) if len(mature) != 0 else 0\n",
    "    calculate_max_bulge_result = calculate_max_bulge(mature_range, star_range, ct_data)\n",
    "    mature_max_bulge, star_max_bulge = calculate_max_bulge_result[\"mature_max_bulge\"], calculate_max_bulge_result[\"star_max_bulge\"]\n",
    "    mature_bulges = calculate_max_bulge_result[\"mature_bulges\"]\n",
    "    star_bulges = calculate_max_bulge_result[\"star_bulges\"]\n",
    "    # mature_max_asymmetry = calculate_bulge_asymmetry(mature_bulges, ct_data , 'mature')\n",
    "    # print('mature',mature_bulges)\n",
    "    # star_max_asymmetry = calculate_bulge_asymmetry(star_bulges, ct_data,'star')\n",
    "    # print('star',star_bulges)\n",
    "    star_connections = count_connections(adjust_index(star_start), adjust_index(star_end), ct_data)\n",
    "    star_bp_ratio = star_connections / len(star) if len(star) != 0 else 0\n",
    "    ug, ugug = find_ug_sequences(decoded_seq, mature_start, mature_end, threshold=10)\n",
    "    hairpin_trimmed = decoded_seq.replace(flank1, '').replace(flank2,'')\n",
    "    h_start = adjust_index(decoded_seq.find(hairpin_trimmed))\n",
    "    h_end = mature_start + len(hairpin_trimmed)\n",
    "    energy = calculate_energy(hairpin_trimmed)\n",
    "    one_mer_mature = calculate_mer_ratios(mature, 1)\n",
    "    two_mer_mature = calculate_mer_ratios(mature, 2)\n",
    "    one_mer_h_trimm = calculate_mer_ratios(hairpin_trimmed, 1)\n",
    "    two_mer_h_trimm = calculate_mer_ratios(hairpin_trimmed, 2)\n",
    "    one_mer_full = calculate_mer_ratios(decoded_seq, 1)\n",
    "    two_mer_full = calculate_mer_ratios(decoded_seq, 2)\n",
    "\n",
    "    feature_dict = {\n",
    "        'full_seq': decoded_seq,\n",
    "        'Mature': mature,\n",
    "        'Mature_length': len(mature),\n",
    "        'Star': star,\n",
    "        'End_star': adjust_index(star_end),\n",
    "        'full_seq_folding': full_seq_folding,\n",
    "        'Loop_seq': loop,\n",
    "        'Loop_length': len(loop),\n",
    "        'flank1': flank1,\n",
    "        'flank2': flank2,\n",
    "        'flank1_length': len(flank1),\n",
    "        'flank2_length': len(flank2),\n",
    "        'Mature_start': adjust_index(mature_start),\n",
    "        'Mature_end': adjust_index(mature_end),\n",
    "        'Star_start': adjust_index(star_start),\n",
    "        'Star_end': adjust_index(star_end),\n",
    "        'Star_length': len(star),\n",
    "        'Mature_length': len(mature),\n",
    "        'Loop_seq_start': loop_start_index,\n",
    "        'Loop_seq_end': loop_end_index,\n",
    "        'flank1_start': flank1_start_index,\n",
    "        'flank1_end': flank1_end_index,\n",
    "        'flank2_start': flank2_start_index,\n",
    "        'flank2_end': flank2_end_index,\n",
    "        'seed': seed,\n",
    "        'seed_start': seed_start,\n",
    "        'seed_end': seed_end,\n",
    "        'seed_family': seed_family,\n",
    "        '3p/5p': direction,\n",
    "        'Mature_connections': mature_connections,\n",
    "        'Mature_Star_connections': mature_star_connections,\n",
    "        'Mature_BP_ratio': round(mature_bp_ratio, 2),\n",
    "        'Mature_max_bulge': mature_max_bulge,\n",
    "        'Star_connections': star_connections,\n",
    "        'Star_BP_ratio': round(star_bp_ratio, 2),\n",
    "        'Star_max_bulge': star_max_bulge,\n",
    "        'UG': ug,\n",
    "        'UGUG': ugug,\n",
    "        'hairpin_trimmed': hairpin_trimmed,\n",
    "        'hairpin_trimmed_length': len(hairpin_trimmed),\n",
    "        'folding_energy': round(energy, 2),\n",
    "        'one_mer_mature': one_mer_mature,\n",
    "        'two_mer_mature': two_mer_mature,\n",
    "        'one_mer_hairpin_trimmed': one_mer_h_trimm ,\n",
    "        'two_mer_hairpin_trimmed': two_mer_h_trimm ,\n",
    "        'one_mer_full': one_mer_full,\n",
    "        'two_mer_full': two_mer_full,\n",
    "    }\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "def process_rna_sequences(rna_sequences):\n",
    "    results = []\n",
    "    invalid_results = []\n",
    "    \n",
    "    summary = {\n",
    "        'multiple_mature': 0,\n",
    "        'multiple_star': 0,\n",
    "        'missing_mature': 0,\n",
    "        'missing_star': 0,\n",
    "        'invalid_dot_bracket': 0,\n",
    "        'invalid_pairs': {},\n",
    "        'total_sequences': len(rna_sequences),\n",
    "        'unique_before_filtering': len(set(rna_sequences)),  # Number of unique sequences before filtering\n",
    "        'unique_after_filtering': 0,  # To be calculated after filtering\n",
    "        'unique_invalid': 0,\n",
    "        'failed_rnafold': 0  \n",
    "    }\n",
    "    \n",
    "    for seq in tqdm(rna_sequences, desc=\"Processing sequences\"):\n",
    "        if 'ZZZZZ' not in seq or 'BBBBB' not in seq:\n",
    "            summary['missing_mature'] += 1\n",
    "        elif seq.count('ZZZZZ') > 1 or seq.count('BBBBB') > 1:\n",
    "            summary['multiple_mature'] += 1\n",
    "\n",
    "        if 'DDDDD' not in seq or 'FFFFF' not in seq:\n",
    "            summary['missing_star'] += 1\n",
    "        elif seq.count('DDDDD') > 1 or seq.count('FFFFF') > 1:\n",
    "            summary['multiple_star'] += 1\n",
    "\n",
    "        parts = retrieve_parts_only_nts(seq)  # Ensure retrieve_parts is defined somewhere\n",
    "        if parts:\n",
    "            if parts == -1:\n",
    "                summary['failed_rnafold'] += 1\n",
    "                continue\n",
    "            is_valid, invalid_pairs = is_valid_dot_bracket(parts['full_seq_folding'], parts['decoded_seq'])\n",
    "            if is_valid:\n",
    "                results.append(parts)\n",
    "            else:\n",
    "                summary['invalid_dot_bracket'] += 1\n",
    "                invalid_result = {'sequence': parts['full_seq_folding'], 'encoded_seq': seq,'invalid_pairs':invalid_pairs}\n",
    "                invalid_result.update(invalid_pairs)\n",
    "                invalid_results.append(invalid_result)\n",
    "                for pair, count in invalid_pairs.items():\n",
    "                    summary['invalid_pairs'][pair] = summary['invalid_pairs'].get(pair, 0) + count\n",
    "\n",
    "    results_df = pd.DataFrame(results).drop_duplicates(subset='decoded_seq')\n",
    "    invalid_results_df = pd.DataFrame(invalid_results)\n",
    "    \n",
    "    # Calculate unique values after filtering\n",
    "    summary['unique_after'] = results_df['decoded_seq'].nunique() if 'decoded_seq' in results_df.columns else 0\n",
    "    summary['unique_invalid'] = invalid_results_df['sequence'].nunique() if 'sequence' in invalid_results_df.columns else 0\n",
    "    \n",
    "    return results_df, invalid_results_df, summary\n",
    "\n",
    "def extract_features_from_df(rna_df):\n",
    "    features = []\n",
    "    # Add tqdm around your loop\n",
    "    for index, row in tqdm(rna_df.iterrows(), total=len(rna_df), desc=\"Extracting features\"):\n",
    "        feature = extract_features_only_nts(row['decoded_seq'], row['full_seq_folding'], row['mature'], row['star'])\n",
    "        if feature:\n",
    "            features.append(feature)\n",
    "\n",
    "    features_df = pd.DataFrame(features)\n",
    "    return features_df\n",
    "\n",
    "def remove_flanks(full_seq, flank1, flank2):\n",
    "    result = full_seq.replace(flank1, \"\").replace(flank2, \"\")\n",
    "    return result\n",
    "    \n",
    "def add_pre_mirna_and_remove_duplicates(rna_df):\n",
    "    rna_df['pre_mirna'] = rna_df.apply(lambda row: remove_flanks(row['full_seq'], row['flank1'], row['flank2']), axis=1)\n",
    "    rna_df = rna_df.drop_duplicates(subset='pre_mirna', keep='first')\n",
    "    return rna_df\n",
    "\n",
    "def remove_duplicates(rna_df):\n",
    "    rna_df['pre_mirna'] = rna_df['full_seq']\n",
    "    rna_df = rna_df.drop_duplicates(subset='pre_mirna', keep='first')\n",
    "    return rna_df\n",
    "\n",
    "    \n",
    "def add_diversity_novelty_to_df(rna_df, real_sequences_no_flanks):\n",
    "    # Calculate local and global diversity scores\n",
    "    tqdm.pandas() # This is for using tqdm with pandas' apply method\n",
    "\n",
    "    rna_df['avg_diversity'], rna_df['max_diversity'] = zip(*rna_df['pre_mirna'].progress_apply( lambda x: calculate_diversity(x, rna_df['pre_mirna'].tolist())))\n",
    "    rna_df['avg_novelty'], rna_df['max_novelty'] = zip(*rna_df['pre_mirna'].progress_apply(lambda x: calculate_novelty(x, real_sequences_no_flanks)))\n",
    "    return rna_df\n",
    "\n",
    "def add_diversity_to_original_df(df, df2):\n",
    "    df['avg_diversity'], df['max_diversity'] = zip(*df['full_seq'].progress_apply( lambda x: calculate_diversity(x, df2['full_seq'].tolist())))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e088b8-79a7-41b1-9f39-b919ff468c64",
   "metadata": {},
   "source": [
    "### Add Pre-mirna & mers & connections columns to original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71479f97-c6ed-4cf5-a721-f3325a6ce16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mers and connections to original data:\n",
    "\n",
    "def extract_features_only_mers(full_seq, full_seq_folding, mature, star):\n",
    "    ct_data = get_ct_data(full_seq, full_seq_folding, \"output_original.ct\")\n",
    "\n",
    "    mature_start = full_seq.find(mature)\n",
    "    mature_end = mature_start + len(mature) - 1  # Adjust to 0-based indexing\n",
    "    star_start = full_seq.find(star)\n",
    "    star_end = star_start + len(star) - 1  # Adjust to 0-based indexing\n",
    "    \n",
    "    if mature_start < 0 or star_start < 0:\n",
    "        print('mature ot start invalid')\n",
    "        return None\n",
    "\n",
    "    if mature_start < star_start:\n",
    "        loop = full_seq[mature_end+1:star_start]\n",
    "        flank1 = full_seq[:mature_start]\n",
    "        flank2 = full_seq[star_end+1:]\n",
    "        direction = '5p'\n",
    "    else:\n",
    "        loop = full_seq[star_end+1:mature_start]\n",
    "        flank1 = full_seq[:star_start]\n",
    "        flank2 = full_seq[mature_end+1:]\n",
    "        direction = '3p'\n",
    "        \n",
    "    hairpin_trimmed = full_seq.replace(flank1, '').replace(flank2,'')\n",
    "    one_mer_mature = calculate_mer_ratios(mature, 1)\n",
    "    two_mer_mature = calculate_mer_ratios(mature, 2)\n",
    "    one_mer_h_trimm = calculate_mer_ratios(hairpin_trimmed, 1)\n",
    "    two_mer_h_trimm = calculate_mer_ratios(hairpin_trimmed, 2)\n",
    "    one_mer_full = calculate_mer_ratios(full_seq, 1)\n",
    "    two_mer_full = calculate_mer_ratios(full_seq, 2)\n",
    "    \n",
    "    mature_star_connections = count_connections_both(adjust_index(mature_start), adjust_index(star_start), adjust_index(mature_end), adjust_index(star_end), ct_data)\n",
    "\n",
    "    feature_dict = {\n",
    "        'one_mer_mature': one_mer_mature,\n",
    "        'two_mer_mature': two_mer_mature,\n",
    "        'one_mer_hairpin_trimmed': one_mer_h_trimm ,\n",
    "        'two_mer_hairpin_trimmed': two_mer_h_trimm ,\n",
    "        'one_mer_full': one_mer_full,\n",
    "        'two_mer_full': two_mer_full,\n",
    "        'Mature_Star_connections': mature_star_connections,\n",
    "    }\n",
    "    \n",
    "    return feature_dict\n",
    "    \n",
    "def extract_mers_from_df(rna_df):\n",
    "    features = []\n",
    "    # Add tqdm around your loop\n",
    "    for index, row in tqdm(rna_df.iterrows(), total=len(rna_df), desc=\"Extracting features\"):\n",
    "        feature = extract_features_only_mers(row['full_seq'], row['full_seq_folding'], row['Mature'], row['Star'])\n",
    "        if feature:\n",
    "            features.append(feature)\n",
    "    new_features_df = pd.DataFrame(features)\n",
    "    features_df = pd.concat([rna_df, new_features_df], axis=1)\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a820681-a000-4528-b6ea-4e33ea08997f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763cd2c5-fda8-4007-be54-1ba9ba85becd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_statistics(sequences):\n",
    "    num_sequences = len(sequences)\n",
    "    avg_length = int(sum(len(seq) for seq in sequences) / num_sequences) # if isinstance(seq, str)\n",
    "    min_length = min(len(seq) for seq in sequences)\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "\n",
    "    return {\n",
    "        \"Number of sequences\": num_sequences,\n",
    "        \"Average sequence length\": avg_length,\n",
    "        \"Min sequence length\": min_length,\n",
    "        \"Max sequence length\": max_length\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2588275-fd1a-4577-a367-6aa2621111bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044a497d-50e8-496c-a1ce-29eb1d2c58e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fasta_to_tuples(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        content = f.read().strip().split(\"\\n\")\n",
    "\n",
    "    sequences = []\n",
    "    for i in range(0, len(content), 2):\n",
    "        header = content[i][1:]  # remove '>'\n",
    "        sequence = content[i+1]\n",
    "        sequences.append((header, sequence))\n",
    "\n",
    "    return sequences\n",
    "\n",
    "def tuples_to_jsonl(sequences, output_filename):\n",
    "    with open(output_filename, 'w') as f:\n",
    "        for header, sequence in sequences:\n",
    "            data = {\n",
    "                \"id\": header,\n",
    "                \"sequence\": sequence\n",
    "            }\n",
    "            f.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b259d-0a41-4cc2-ab64-fe48754270bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72176350-dcbd-4b89-a9c5-a01f7f8783cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/generated_100_test_human.txt', 'r') as f: # genreated_new_10000_human_mirgenedb_gff_ms, 'genreated_52_split_human_mirgenedb_gff_ms.txt'\n",
    "    generated_sequences = f.readlines()\n",
    "real_sequences_path = '/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/seq_clusters/human_test_full_seqs.txt'\n",
    "with open(real_sequences_path, \"r\") as file:\n",
    "    real_sequences = file.readlines()\n",
    "generated_sequences = [s.strip() for s in generated_sequences] ; real_sequences = [s.strip() for s in real_sequences]\n",
    "generated_sequences = [s for s in generated_sequences if 'N' not in s]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db9c2d-a51d-4a25-9417-5ac1ab609977",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### All data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11f9aab-120d-41f9-9551-faf8e6e07ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ZZZZZTATACCTCAGTTTTATCAGGTGBBBBBTTCTTAAAATCADDDDDCCTGGAAACACTGAGGTTGTGTFFFFF',\n",
       " 'GAAGAAGAAGACCCAAUGCCCGGGGAGAAGUACGGUGAGCCUGUCAUUAUUCAGAGAGGCUAGAUCCUCUGUGUUGAGAAGGAUCAUGAUGGGCUCCUCGGUGUUCUCCAGGUAGCGGCACCACACCAUGAAGG',\n",
       " 'UGAGGUAGUAGUUUGUGCUGUUGGUCGGGUUGUGACAUUGCCCGCUGUGGAGAUAACUGCGCAAGCUACUGCCUUGC')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/generated_100_full_data_hairpin_human.txt', 'r') as f: # genreated_new_10000_human_no_flanks_mirgenedb_gff_ms / genreated_new_10000_human_mirgenedb_gff_ms, 'genreated_52_split_human_mirgenedb_gff_ms.txt'\n",
    "    generated_sequences = f.readlines()\n",
    "with open('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/human_fine_tuned_original_data.txt', 'r') as f: # \n",
    "    real_sequences = f.readlines()\n",
    "    # # # without flanks:\n",
    "human_data_fasta = fasta_to_tuples(\"/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/Data_source/miRGeneDB/precursors_human_no_flank.fas.txt\")\n",
    "real_sequences_no_flanks = [s[1] for s in human_data_fasta]\n",
    "real_sequences_no_flanks = [s.strip() for s in real_sequences_no_flanks]\n",
    "# Remove the newline characters at the end of each line\n",
    "generated_sequences = [s.strip() for s in generated_sequences] ; real_sequences = [s.strip() for s in  real_sequences]\n",
    "generated_sequences = [s for s in generated_sequences if 'N' not in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c2092f-ba73-4453-8a00-50a6aa566aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|██████████| 100/100 [00:00<00:00, 175.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./generated_human_all_data_hairpin_seq\n",
      "Summary: {'multiple_mature': 6, 'multiple_star': 2, 'missing_mature': 12, 'missing_star': 8, 'invalid_dot_bracket': 0, 'invalid_pairs': {}, 'total_sequences': 100, 'unique_before_filtering': 100, 'unique_after_filtering': 0, 'unique_invalid': 0, 'failed_rnafold': 0, 'unique_after': 80}\n",
      "Invalid Results:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "rna_sequences = generated_sequences\n",
    "rna_df, invalid_results_df, summary = process_rna_sequences(rna_sequences)\n",
    "\n",
    "# # Create directory for results if it doesn't exist\n",
    "output_dir = \"./generated_human_all_data_hairpin_seq\" #generated_human_test_seq / generated_no_flanks_results_only_nts / generated_spilt_52_results_only_nts\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save results to CSV files\n",
    "rna_df.to_csv(os.path.join(output_dir, \"human_gen_all_sequences.csv\"), index=False) # rna_sequences #intermidiate results only with parts \n",
    "invalid_results_df.to_csv(os.path.join(output_dir, \"invalid_sequences_human_all_gen.csv\"), index=False) #invalid_sequences # invalid sequences with \n",
    "\n",
    "# Save summary to a JSON file\n",
    "with open(os.path.join(output_dir, \"summary_human_all_gen.json\"), 'w') as f:  #summary / summary_human_gen_completion_hairpin\n",
    "    json.dump(summary, f)\n",
    "\n",
    "print(\"Results saved to\", output_dir)\n",
    "print(\"Summary:\", summary)\n",
    "print(\"Invalid Results:\")\n",
    "print(invalid_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74040ef8-bfc6-481c-ab92-05d09f55d7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features and save to CSV\n",
    "features_df = extract_features_from_df(rna_df)\n",
    "print('Finish extract features\\nAdding diversity values:')\n",
    "# features_df = add_diversity_to_df(features_df, real_sequences)\n",
    "\n",
    "# no flanks - only pre-mirna\n",
    "# to check the diversity and novelity between the sequences without considering the flanks:\n",
    "# features_df = add_pre_mirna_and_remove_duplicates(features_df) # with flanks\n",
    "# features_df = remove_duplicates(features_df)  # for no flanks\n",
    "\n",
    "# features_df = add_diversity_novelty_to_df(features_df, real_sequences)\n",
    "features_df.to_csv(os.path.join(output_dir, \"gen_human_test_features.csv\"), index=False)\n",
    "features_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT_ron",
   "language": "python",
   "name": "gpt_ron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
