{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tokenizers\n",
        "!pip install -q transformers\n",
        "!pip install -q tokenizers"
      ],
      "metadata": {
        "id": "6WmEwEht6DXF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n"
      ],
      "metadata": {
        "id": "bDYZquklilTe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# True if no flanks\n",
        "hairpin_bool = False\n",
        "if hairpin_bool:\n",
        "  relevant_seq = 'pre_mirna'\n",
        "else:\n",
        "  relevant_seq = 'full_seq'"
      ],
      "metadata": {
        "id": "3wvLXBsVVXxG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all data:\n",
        "# gff_data = pd.read_csv('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/Data_output/gff_output/sebastian_db_features_new.csv')\n",
        "# mirogen_data = pd.read_csv('/sise/vaksler-group/IsanaRNA/Transformers/Rom/Data_output/miRGeneDB_output/miRGeneDB_features.csv')\n",
        "\n",
        "# train data:\n",
        "gff_data = pd.read_csv('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/seq_clusters/gff_train_data.csv')\n",
        "mirogen_data = pd.read_csv('/sise/vaksler-group/IsanaRNA/Transformers/GPT_env/seq_clusters/mirgene_train_data.csv.csv')\n",
        "\n",
        "# # remove the flanks from the sequences:\n",
        "# gff_data = gff_data.dropna(subset=['full_seq', 'flank1', 'flank2']); mirogen_data = mirogen_data.dropna(subset=['full_seq', 'flank1', 'flank2']) # found some null flanks\n",
        "# for index, row in gff_data.iterrows():\n",
        "#     gff_data.at[index, 'full_seq'] = gff_data.at[index, 'full_seq'].replace(row['flank1'], '').replace(row['flank2'], '')\n",
        "# for index, row in mirogen_data.iterrows():\n",
        "#     mirogen_data.at[index, 'full_seq'] = mirogen_data.at[index, 'full_seq'].replace(row['flank1'], '').replace(row['flank2'], '')\n",
        "\n",
        "original_gff_sequences = gff_data[relevant_seq].tolist() ; original_mirogen_sequences  = mirogen_data[relevant_seq].tolist()\n",
        "gff_data = gff_data.dropna(subset=['Star','Mature']); mirogen_data = mirogen_data.dropna(subset=['Star','Mature']) # found some null star and mature\n",
        "\n",
        "\n",
        "def encode_sequence(row):\n",
        "    full_seq = row[relevant_seq]\n",
        "    mature_start = full_seq.find(row['Mature'])\n",
        "    mature_end = mature_start + len(row['Mature'])\n",
        "    star_start = full_seq.find(row['Star'])\n",
        "    star_end = star_start + len(row['Star'])\n",
        "    # star_end = len(row['Star'])\n",
        "\n",
        "    encoded_seq = full_seq\n",
        "    if star_start < star_end:\n",
        "        if mature_start < star_start:\n",
        "            encoded_seq = (encoded_seq[:mature_start] + 'ZZZZZ' +\n",
        "                           encoded_seq[mature_start:mature_end] + 'BBBBB' +\n",
        "                           encoded_seq[mature_end:star_start] + 'DDDDD' +\n",
        "                           encoded_seq[star_start:star_end] + 'FFFFF' +\n",
        "                           encoded_seq[star_end:])\n",
        "        else:\n",
        "            encoded_seq = (encoded_seq[:star_start] + 'DDDDD' +\n",
        "                           encoded_seq[star_start:star_end] + 'FFFFF' +\n",
        "                           encoded_seq[star_end:mature_start] + 'ZZZZZ' +\n",
        "                           encoded_seq[mature_start:mature_end] + 'BBBBB' +\n",
        "                           encoded_seq[mature_end:])\n",
        "    return encoded_seq\n",
        "\n",
        "\n",
        "def decode_sequence(encoded_seq):\n",
        "    decoded_seq = encoded_seq.replace('ZZZZZ', '').replace('BBBBB', '').replace('DDDDD', '').replace('FFFFF', '')\n",
        "    return decoded_seq\n",
        "\n",
        "\n",
        "# Apply the encoding function on both datasets\n",
        "gff_data['encoded_seq'] = gff_data.apply(encode_sequence, axis=1) ; mirogen_data['encoded_seq'] = mirogen_data.apply(encode_sequence, axis=1)\n",
        "\n",
        "# gff_data['encoded_seq'] = gff_data.apply(encode_sequence, axis=1) ; mirogen_data['encoded_seq'] = mirogen_data.apply(encode_sequence, axis=1)\n",
        "gff_data['decoded_seq'] = gff_data['encoded_seq'].apply(decode_sequence) ; mirogen_data['decoded_seq'] = mirogen_data['encoded_seq'].apply(decode_sequence)"
      ],
      "metadata": {
        "id": "KKNcFy44isfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((gff_data[relevant_seq] == gff_data['decoded_seq']).value_counts())\n",
        "# Iterate through the sampled false indices and check each point\n",
        "# get sampled_false_indices (where gff_data['full_seq'] != gff_data['decoded_seq'])\n",
        "false_indices = [idx for idx in gff_data[gff_data[relevant_seq] != gff_data['decoded_seq']].index]\n",
        "sampled_false_indices = np.random.choice(false_indices, 3, replace=False)\n",
        "for idx in sampled_false_indices:\n",
        "    print(\"Index:\", idx)\n",
        "\n",
        "    # Extract necessary information from the DataFrame\n",
        "    row = gff_data.loc[idx]\n",
        "    full_seq = row[relevant_seq]\n",
        "    # full_seq_folding = row['full_seq_folding'] ################################################\n",
        "    encoded_seq = row['encoded_seq']\n",
        "    decoded_seq = row['decoded_seq']\n",
        "\n",
        "    # 1. Check Special Encoding Tokens\n",
        "    # Check if special tokens are correctly replaced during decoding\n",
        "    if 'ZZZZZ' in decoded_seq or 'BBBBB' in decoded_seq or 'DDDDD' in decoded_seq or 'FFFFF' in decoded_seq:\n",
        "        print(\"Special Encoding Tokens not correctly replaced.\")\n",
        "\n",
        "    # 2. Check Start and End Indices\n",
        "    # Print the start and end indices used during encoding\n",
        "    mature_start = full_seq.find(row['Mature'])\n",
        "    mature_end = mature_start + len(row['Mature'])\n",
        "    star_start = row['Start_star']\n",
        "    star_end = row['End_star']\n",
        "    print(\"Mature Start:\", mature_start, \"Mature End:\", mature_end)\n",
        "    print(\"Star Start:\", star_start, \"Star End:\", star_end)\n",
        "    # Print the Decoded, Encoded, and Full Sequence for comparison\n",
        "    print(\"Encoded Sequence:\", encoded_seq)\n",
        "    print(\"Decoded Sequence:\", decoded_seq)\n",
        "    print(\"full/hairpin Sequence:\", full_seq)\n",
        "    print('len(decoded_seq):', len(decoded_seq))\n",
        "    print('len(full/hairpin seq):', len(full_seq))\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xSSsUNVi8-n",
        "outputId": "5f53bb3e-6e88-4b9c-9990-73e5acf41603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True     23711\n",
            "False      129\n",
            "dtype: int64\n",
            "Index: 22610\n",
            "Mature Start: 50 Mature End: 72\n",
            "Star Start: 1.0 Star End: 35.0\n",
            "Encoded Sequence: atatcatataatatataatatatcaGACATDDDDDAAGGCAACGTGCCACTGATATGATAATTTATCATAFFFFFZZZZZTGATAATTTATCATATCAGTGGBBBBBCACGTTGCCTTATGTCTGATCGTTCGATGAGGGAAAAGCTTGG\n",
            "Decoded Sequence: atatcatataatatataatatatcaGACATAAGGCAACGTGCCACTGATATGATAATTTATCATATGATAATTTATCATATCAGTGGCACGTTGCCTTATGTCTGATCGTTCGATGAGGGAAAAGCTTGG\n",
            "full/hairpin Sequence: atatcatataatatataatatatcaGACATAAGGCAACGTGCCACTGATATGATAATTTATCATATCAGTGGCACGTTGCCTTATGTCTGATCGTTCGATGAGGGAAAAGCTTGG\n",
            "len(decoded_seq): 130\n",
            "len(full/hairpin seq): 115\n",
            "------------------------------\n",
            "Index: 13878\n",
            "Mature Start: 42 Mature End: 64\n",
            "Star Start: 1.0 Star End: 53.0\n",
            "Encoded Sequence: AGTGCTGGAGCAAGAAGATCTCGTGCTGCGDDDDDACTCTACAAAGGAAAGTGCTTTCTGTTGCCAGAAAGAAGAGAAAGCGCTTCCCFFFFFZZZZZAAAGTGCTTTCTGTTGCCAGAABBBBBAGAAGAGAAAGCGCTTCCCTTTTGAGGGTTACGGTTTGAGAAAAGCAGTGTTGAAGTTG\n",
            "Decoded Sequence: AGTGCTGGAGCAAGAAGATCTCGTGCTGCGACTCTACAAAGGAAAGTGCTTTCTGTTGCCAGAAAGAAGAGAAAGCGCTTCCCAAAGTGCTTTCTGTTGCCAGAAAGAAGAGAAAGCGCTTCCCTTTTGAGGGTTACGGTTTGAGAAAAGCAGTGTTGAAGTTG\n",
            "full/hairpin Sequence: AGTGCTGGAGCAAGAAGATCTCGTGCTGCGACTCTACAAAGGAAAGTGCTTTCTGTTGCCAGAAAGAAGAGAAAGCGCTTCCCTTTTGAGGGTTACGGTTTGAGAAAAGCAGTGTTGAAGTTG\n",
            "len(decoded_seq): 164\n",
            "len(full/hairpin seq): 123\n",
            "------------------------------\n",
            "Index: 20591\n",
            "Mature Start: 50 Mature End: 72\n",
            "Star Start: 1.0 Star End: 41.0\n",
            "Encoded Sequence: CAAAAGTGAAGAATCTAAGGGCTGACTGGGDDDDDTAATCTCTGCAGGCAACTGTGACGGTGCTTTAAATTCTCACFFFFFZZZZZGACGGTGCTTTAAATTCTCACABBBBBATGACCTGGAGAGATTCTGCAGTTGCCTTTTATAACTTGAAAACACGAT\n",
            "Decoded Sequence: CAAAAGTGAAGAATCTAAGGGCTGACTGGGTAATCTCTGCAGGCAACTGTGACGGTGCTTTAAATTCTCACGACGGTGCTTTAAATTCTCACAATGACCTGGAGAGATTCTGCAGTTGCCTTTTATAACTTGAAAACACGAT\n",
            "full/hairpin Sequence: CAAAAGTGAAGAATCTAAGGGCTGACTGGGTAATCTCTGCAGGCAACTGTGACGGTGCTTTAAATTCTCACAATGACCTGGAGAGATTCTGCAGTTGCCTTTTATAACTTGAAAACACGAT\n",
            "len(decoded_seq): 142\n",
            "len(full/hairpin seq): 121\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gff_sequences = ['<SOS>' + sequence + '<EOS>' for sequence in gff_data['encoded_seq']]\n",
        "mirgendb_sequences = ['<SOS>' + sequence + '<EOS>' for sequence in mirogen_data['encoded_seq']]"
      ],
      "metadata": {
        "id": "C5oVdcFzi5is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_statistics(sequences):\n",
        "    num_sequences = len(sequences)\n",
        "    avg_length = int(sum(len(seq) for seq in sequences) / num_sequences)\n",
        "    min_length = min(len(seq) for seq in sequences)\n",
        "    max_length = max(len(seq) for seq in sequences)\n",
        "\n",
        "    return {\n",
        "        \"Number of sequences\": num_sequences,\n",
        "        \"Average sequence length\": avg_length,\n",
        "        \"Min sequence length\": min_length,\n",
        "        \"Max sequence length\": max_length\n",
        "\n",
        "    }"
      ],
      "metadata": {
        "id": "5J0dRNDTypbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre mirna\n",
        "print(calculate_statistics(gff_sequences))\n",
        "print(calculate_statistics(mirgendb_sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jxlVBIUySak",
        "outputId": "b569c0f7-1afc-416e-89b5-d8a3ee1617e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Number of sequences': 23840, 'Average sequence length': 150, 'Min sequence length': 135, 'Max sequence length': 202}\n",
            "{'Number of sequences': 9747, 'Average sequence length': 150, 'Min sequence length': 139, 'Max sequence length': 164}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def token_statistics(tokenizer, sequences):\n",
        "    token_lengths = []\n",
        "\n",
        "    for seq in sequences:\n",
        "        tokens = tokenizer.encode(seq).tokens\n",
        "        token_lengths.extend([len(token) for token in tokens])\n",
        "\n",
        "    avg_length = np.mean(token_lengths)\n",
        "    min_length = np.min(token_lengths)\n",
        "    max_length = np.max(token_lengths)\n",
        "    median_length = np.median(token_lengths)\n",
        "    std_dev = np.std(token_lengths)\n",
        "\n",
        "    return {\n",
        "        \"average\": avg_length,\n",
        "        \"min\": min_length,\n",
        "        \"max\": max_length,\n",
        "        \"median\": median_length,\n",
        "        \"std_dev\": std_dev\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "W546IX3FjetO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bpe_tokenizer(sequences, vocab_size=10000, min_frequency=3):\n",
        "    special_tokens = [\"<SOS>\", \"<EOS>\", \"ZZZZZ\", \"BBBBB\", \"DDDDD\", \"FFFFF\"]\n",
        "\n",
        "    # Define BPE model with an unknown token\n",
        "    tokenizer = Tokenizer(BPE(unk_token=\"<UNK>\"))\n",
        "\n",
        "    # Define the BPE trainer with special tokens, vocab size, and min frequency\n",
        "    trainer =  BpeTrainer(special_tokens=special_tokens, max_token_length=6) #vocab_size=vocab_size, min_frequency=min_frequency,\n",
        "    # Train the tokenizer from the iterator of sequences\n",
        "    tokenizer.train_from_iterator(sequences, trainer=trainer)\n",
        "\n",
        "    # After training, add the special tokens to the tokenizer to ensure they won't be split\n",
        "    tokenizer.add_tokens(special_tokens)\n",
        "\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "zWpatVLNjf4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bpe_tokenizer = train_bpe_tokenizer(gff_sequences + mirgendb_sequences, vocab_size=10000, min_frequency=3)\n",
        "bpe_tokenizer.save(\"data/GPT_mature_star_bpe_tokenizer.json\") # GPT_mature_star_bpe_hairpin_tokenizer / with flanks : \"GPT_mature_star_bpe_tokenizer\""
      ],
      "metadata": {
        "id": "1tr-JKMljhMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sequences = np.random.choice(gff_sequences,5,replace=False)\n",
        "for seq in sample_sequences:\n",
        "    # print(seq)\n",
        "    encoded = bpe_tokenizer.encode(seq)\n",
        "    print(f\"Original: {seq}\")\n",
        "    print(f\"Encoded: {encoded.tokens}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuffxcCNkFz7",
        "outputId": "e262e629-88a3-47cd-dcc6-305a94724453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: <SOS>DDDDDCCGGACGAACTTCCCAGCTCGGCCFFFFFGACATGAACGGGZZZZZTCGGTGGGATCTTCGTCCGTTTBBBBB<EOS>\n",
            "Encoded: ['<SOS>', 'DDDDD', 'CCGGA', 'CGAA', 'CTTCC', 'CAGC', 'TCGG', 'CC', 'FFFFF', 'GA', 'CATG', 'AA', 'CGGG', 'ZZZZZ', 'TC', 'GGTG', 'GGATC', 'TTC', 'GTC', 'CGTTT', 'BBBBB', '<EOS>']\n",
            "\n",
            "Original: <SOS>DDDDDAGGTTGGGATGTGTGCATTATTTGFFFFFTGGAAGGTTAGATCAZZZZZAATTGCACTCGTCCCGGCCTGCBBBBB<EOS>\n",
            "Encoded: ['<SOS>', 'DDDDD', 'AGG', 'TTG', 'GGA', 'TGTG', 'TGCA', 'TTA', 'TTTG', 'FFFFF', 'TGGAA', 'GG', 'TTAGA', 'TCA', 'ZZZZZ', 'AA', 'TTGCA', 'CTC', 'GTC', 'CCGG', 'CCTGC', 'BBBBB', '<EOS>']\n",
            "\n",
            "Original: <SOS>DDDDDAGTTCTTCACTGGCAAGCTTTAFFFFFTGTCCTCATGTACCAACTAZZZZZAAGCTGCCAGCTGAAGAACTGTBBBBB<EOS>\n",
            "Encoded: ['<SOS>', 'DDDDD', 'AGTT', 'CTT', 'CACTG', 'GCAA', 'GC', 'TTTA', 'FFFFF', 'TGTC', 'CTCA', 'TGTA', 'CCAA', 'CTA', 'ZZZZZ', 'AA', 'GCTG', 'CCA', 'GCTG', 'AAGAA', 'CTGT', 'BBBBB', '<EOS>']\n",
            "\n",
            "Original: <SOS>AZZZZZACCCGTAGATCCGAACTTGTGTBBBBBTGTCTGGCCACDDDDDACAAGCTCGTGTCTATAGGTATGFFFFF<EOS>\n",
            "Encoded: ['<SOS>', 'A', 'ZZZZZ', 'ACC', 'CGTA', 'GATCC', 'GAA', 'CTTG', 'TGT', 'BBBBB', 'TG', 'TCTG', 'GCCAC', 'DDDDD', 'ACAA', 'GCTC', 'GTG', 'TCTA', 'TAGG', 'TATG', 'FFFFF', '<EOS>']\n",
            "\n",
            "Original: <SOS>ZZZZZTACAGTGATCAGGTTATGATGGBBBBBATTTCTCAAGTAACAACCDDDDDTCGTAGCTTGATCACGATATCFFFFF<EOS>\n",
            "Encoded: ['<SOS>', 'ZZZZZ', 'TACA', 'GTGA', 'TCAGG', 'TTA', 'TGATG', 'G', 'BBBBB', 'ATTTC', 'TCAA', 'GTAA', 'CAACC', 'DDDDD', 'TCGTA', 'GC', 'TTGA', 'TCA', 'CGA', 'TATC', 'FFFFF', '<EOS>']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}