{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9ca498-45ad-41f6-b960-fe641775de96",
   "metadata": {},
   "source": [
    "# GPT_project - prepare_data_01.ipynb \n",
    "###  1 . get data from bastian gff files \n",
    "### 2. filter the dataset by specific conditiens \n",
    "### 3. find Star location by the mature position\n",
    "### 4. extract biological features \n",
    "### 5. get statistics and preapare final dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94ac770c-c92e-4faa-86ab-6d4ea16a5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a379e670-b337-4c69-b6cd-c609865356df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 gffs processed.\n",
      "100 gffs processed.\n",
      "200 gffs processed.\n",
      "300 gffs processed.\n",
      "400 gffs processed.\n",
      "500 gffs processed.\n",
      "600 gffs processed.\n",
      "700 gffs processed.\n",
      "800 gffs processed.\n",
      "900 gffs processed.\n",
      "1000 gffs processed.\n",
      "1100 gffs processed.\n",
      "1200 gffs processed.\n",
      "Processing complete. Output saved to ./Data_output/gff_output/bastian_db_features_new_2.csv\n",
      "(2253, 29800)\n"
     ]
    }
   ],
   "source": [
    "def build_dict():\n",
    "    \"\"\"\n",
    "    Build and return an empty dictionary with predefined keys.\n",
    "    \n",
    "    :return: Empty dictionary with keys\n",
    "    \"\"\"\n",
    "    keys = ['Chr', 'Start_hairpin', 'End_hairpin', 'Strand', 'Hairpin_seq', 'Mature_connections', 'Mature_BP_ratio',\n",
    "            'Mature_max_bulge', 'Loop_length', 'Valid mir', 'Loop_seq', 'Mature', 'Mature_Length', 'Mature2', '3p/5p',\n",
    "            'Hairpin_seq_trimmed', 'Star', 'Start_star', 'End_star', 'Star_length', 'Star_connections', 'Star_BP_ratio',\n",
    "            'Star_max_bulge', 'Hairpin_seq_trimmed_length', 'Window', 'Max_bulge_symmetry', 'full_seq',\n",
    "            'full_seq_folding',\n",
    "            'seed', 'flank1', 'flank2', 'UG', 'UGUG']\n",
    "    return {i: [] for i in keys}\n",
    "\n",
    "def parse_gff_file(gff_file_path, seed_family_dict):\n",
    "    with open(gff_file_path) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Extract metadata\n",
    "    metadata = {}\n",
    "    for line in lines:\n",
    "        if line.startswith(\"# \") and not line.startswith(\"##\"):\n",
    "            try:\n",
    "                key, value = line.strip(\"# \").split(\":\", 1)\n",
    "                metadata[key.strip()] = value.strip()\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    genome_file = metadata.get('Genome file', 'Unknown')\n",
    "    species = metadata.get('Species', 'Unknown')\n",
    "    \n",
    "    data = []\n",
    "    filtered_count = 0 ; more_than_once = 0\n",
    "    for line in lines:\n",
    "        if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "            continue\n",
    "        try:\n",
    "            parts = line.split(\"\\t\")\n",
    "            attributes = dict(attr.split(\"=\") for attr in parts[-1].split(\";\") if \"=\" in attr)\n",
    "            gene_id = attributes.get(\"gene_id\", \"\").replace(\".PRE\", \"\")\n",
    "            full_seq = attributes.get(\"sequence_with_30nt\", \"\").replace('\\n','')\n",
    "            hairpin_trimmed = full_seq[30:-30]\n",
    "            # print(hairpin_trimmed)\n",
    "            seeds = [seed for seed in seed_family_dict.get(gene_id.upper(), []) if seed in hairpin_trimmed]\n",
    "            if seeds:\n",
    "                chosen_seed = seeds[0]  # Select the first seed if multiple are found\n",
    "                seed_start = hairpin_trimmed.find(chosen_seed)\n",
    "                seed_end = seed_start + len(chosen_seed)\n",
    "                mature = hairpin_trimmed[max(0, seed_start-1):min(len(hairpin_trimmed), seed_end+14)]\n",
    "                if hairpin_trimmed.count(chosen_seed) == 1:\n",
    "                    data.append([full_seq, gene_id, genome_file, species, hairpin_trimmed, chosen_seed, mature])  # Adding count as 1\n",
    "                else:\n",
    "                    more_than_once +=1\n",
    "            else:\n",
    "                filtered_count +=1\n",
    "            # If no seed is found, do not add the row to data or count in hairpin greater than 1 \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line: {line}\\nError: {e}\")\n",
    "    if data:\n",
    "        df = pd.DataFrame(data, columns=['full_seq', 'gene_id', 'Genome file', 'Species', 'hairpin_trimmed', 'seed', 'mature'])\n",
    "    else:\n",
    "        # Return an empty DataFrame with the expected columns if no data was added\n",
    "        df = pd.DataFrame(columns=['full_seq', 'gene_id', 'Genome file', 'Species', 'hairpin_trimmed', 'seed', 'mature'])\n",
    "\n",
    "    # No need to filter out rows without a seed as they were never added to the data list\n",
    "    return df, (filtered_count,more_than_once)\n",
    "\n",
    "def run_features_on_sebastian_db_yuval(gff_path, output_path, seed_family_csv_path):\n",
    "    # Read seed family dictionary\n",
    "    features_dict = build_dict()\n",
    "    seed_family_df = pd.read_csv(seed_family_csv_path, encoding='ISO-8859-1')\n",
    "    seed_family_df['Seed'] = seed_family_df['Seed'].apply(lambda x: x.replace('U', 'T') if isinstance(x, str) else x)\n",
    "    seed_family_dict = seed_family_df.groupby('Family')['Seed'].apply(list).to_dict()\n",
    "\n",
    "    all_dfs = []\n",
    "    more_than_once = 0 ; filtered_count =0\n",
    "    for i, gff_filename in enumerate(os.listdir(gff_path)):\n",
    "        if gff_filename.endswith('.gff'):\n",
    "            gff_file_path = os.path.join(gff_path, gff_filename)\n",
    "            df, counts = parse_gff_file(gff_file_path, seed_family_dict)\n",
    "            more_than_once += counts[1] ;filtered_count+=counts[0]\n",
    "            all_dfs.append(df)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f'{i} gffs processed.')\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    gff_data = pd.concat(all_dfs, ignore_index=True)\n",
    "    gff_data.to_csv(output_path, index=False)\n",
    "    print(f\"Processing complete. Output saved to {output_path}\")\n",
    "    return (more_than_once,filtered_count)\n",
    "\n",
    "\n",
    "\n",
    "seed_family_csv = \"./Data_source/seed_family_from_mirgendb.csv\"\n",
    "counts = run_features_on_sebastian_db_yuval(\"./Data_source/gff\",'./Data_output/gff_output/bastian_db_features_new_2.csv', seed_family_csv)\n",
    "print(counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177332d-e67b-402b-ba3f-b6968592b0fd",
   "metadata": {},
   "source": [
    "## First Filter Bastian Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28530cd-8f2f-4d83-a478-f6d7c7c8366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Data_output/gff_output/filtered_counts.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "bastian_df = pd.read_csv('./Data_output/gff_output/bastian_db_features_new_2.csv')\n",
    "mirgene_db = pd.read_csv('./Data_output/miRGeneDB_output/miRGeneDB_features.csv')\n",
    "\n",
    "# add lengthes \n",
    "\n",
    "bastian_df['mature_len'] =bastian_df['mature'].apply(lambda x: len(x))\n",
    "bastian_df['hairpin_trimmed_len'] =bastian_df['hairpin_trimmed'].apply(lambda x: len(x))\n",
    "bastian_df['full_seq_len'] =bastian_df['full_seq'].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "# Analyze the `hairpin_trimmed` column lengths\n",
    "hairpin_lengths = bastian_df['hairpin_trimmed'].str.len()\n",
    "# Filter based on `hairpin_trimmed` length\n",
    "filtered_by_length = bastian_df[(hairpin_lengths >= 45) & (hairpin_lengths <= 65)]\n",
    "\n",
    "# Filter based on sequence presence in `miRGeneDB`\n",
    "mirgene_sequences = set(mirgene_db['full_seq'])\n",
    "filtered_by_presence =  filtered_by_length[~filtered_by_length['full_seq'].isin(mirgene_sequences)]\n",
    "\n",
    "# Filter based on mature sequence length\n",
    "filtered_by_mature_length = filtered_by_presence[filtered_by_presence['mature'].str.len() == 22]\n",
    "\n",
    "# Count rows filtered by each criterion\n",
    "count_length_filtered = len(bastian_df) - len(filtered_by_length)\n",
    "count_presence_filtered = len(filtered_by_length) - len(filtered_by_presence)\n",
    "count_mature_length_filtered = len(filtered_by_presence) - len(filtered_by_mature_length)\n",
    "\n",
    "# Save filtered counts and reasons to a text file\n",
    "with open('./Data_output/gff_output/filtered_counts.txt', 'w') as f:\n",
    "    f.write(f\"Rows filtered by length: (less than 45 more than 65): {count_length_filtered}\\n\")\n",
    "    f.write(f\"Rows filtered by presence in miRGeneDB: {count_presence_filtered}\\n\")\n",
    "    f.write(f\"Rows filtered by mature sequence not being 22: {count_mature_length_filtered}\\n\")\n",
    "\n",
    "\n",
    "# Provide path to the output file for the user to download\n",
    "'./Data_output/gff_output/filtered_counts.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07749ba-e506-48e1-aa8f-4ae54cac5a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170861, 130671, 16266, 116776)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_by_length) , len(filtered_by_presence) , len(bastian_df) - len(filtered_by_length), len(filtered_by_mature_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de96c0-6447-48f8-920f-9d5dd1496c7f",
   "metadata": {},
   "source": [
    "## Find Star By Mature Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0a35bf-1a98-4489-b79c-2fd1eece6dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66967/633444273.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mirmachine_after_filters['star'] = None\n",
      "/tmp/ipykernel_66967/633444273.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mirmachine_after_filters['star_start'] = None\n",
      "/tmp/ipykernel_66967/633444273.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mirmachine_after_filters['star_length'] = None\n",
      "/tmp/ipykernel_66967/633444273.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mirmachine_after_filters['hairpin_folding'] = None\n",
      "  0%|          | 0/116776 [00:00<?, ?it/s]/tmp/ipykernel_66967/633444273.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mirmachine_after_filters.at[index, 'mature_start'] = int(mature_start)+ 1\n",
      "100%|██████████| 116776/116776 [04:31<00:00, 430.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to compute the secondary structure and find the STAR sequence\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import RNA\n",
    "\n",
    "mirmachine_after_filters = filtered_by_mature_length\n",
    "def find_star_sequence(hairpin, mature):\n",
    "    # Compute the secondary structure\n",
    "    ss, _ = RNA.fold(hairpin)\n",
    "    pairing_list = RNA.ptable(ss)\n",
    "    mature_start = hairpin.find(mature)\n",
    "\n",
    "    # Determine the direction of the mature sequence\n",
    "    if mature_start <= 5:\n",
    "        direction = '5p'\n",
    "    else:\n",
    "        direction = '3p'\n",
    "\n",
    "    # Initialize variables\n",
    "    star_start = None\n",
    "    star_end = None\n",
    "\n",
    "    # Logic for finding the STAR sequence start and end\n",
    "    if direction == '5p':\n",
    "        # Find the end of the STAR sequence for mature at the start\n",
    "        paired_pos = pairing_list[mature_start + len(mature)]\n",
    "        if paired_pos != 0:\n",
    "            # STAR sequence starts two nucleotides after the paired position\n",
    "            star_start = paired_pos + 2 -1 \n",
    "        else:\n",
    "            # Find the next paired nucleotide if the last of mature is not paired\n",
    "            for i in range(len(mature) - 1, -1, -1):\n",
    "                if pairing_list[mature_start + i] != 0:\n",
    "                    dist = len(mature) - i \n",
    "                    star_start = pairing_list[mature_start + i] + 2 - dist - 1\n",
    "                    break\n",
    "    else:\n",
    "        # Mature is at the end, find the start of the STAR sequence\n",
    "        paired_pos = pairing_list[mature_start]\n",
    "        if paired_pos != 0:\n",
    "            # STAR sequence ends two nucleotides before the paired position\n",
    "            star_end = paired_pos + 2 -1 \n",
    "        else:\n",
    "            # Find the next paired nucleotide if the first of mature is not paired\n",
    "            for i in range(len(mature)):\n",
    "                if pairing_list[mature_start + i] != 0:\n",
    "                    star_end = pairing_list[mature_start + i] - 2 + i -1 \n",
    "                    break\n",
    "\n",
    "    # Adjusting the logic for extracting the STAR sequence based on direction and the new logic\n",
    "    star_sequence = None\n",
    "    if direction == '5p' and star_start is not None:\n",
    "        star_sequence = hairpin[star_start:]\n",
    "    elif direction == '3p' and star_end is not None:\n",
    "        star_sequence = hairpin[:star_end]\n",
    "        star_start = 0  # STAR starts at the beginning of the hairpin for 3p direction\n",
    "\n",
    "    if star_sequence:\n",
    "        star_length = len(star_sequence)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return star_sequence, star_start, star_length, ss, mature_start\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "mirmachine_after_filters['star'] = None\n",
    "mirmachine_after_filters['star_start'] = None\n",
    "mirmachine_after_filters['star_length'] = None\n",
    "mirmachine_after_filters['hairpin_folding'] = None\n",
    "mirmachine_after_filters  = mirmachine_after_filters\n",
    "for index, row in tqdm(mirmachine_after_filters.iterrows(), total=mirmachine_after_filters.shape[0]):\n",
    "    results = find_star_sequence(row['hairpin_trimmed'], row['mature']) \n",
    "    if results:\n",
    "        star_sequence, star_start, star_length,fold,mature_start = results\n",
    "        mirmachine_after_filters.at[index, 'star'] = star_sequence\n",
    "        mirmachine_after_filters.at[index, 'star_start'] = int(star_start) + 1\n",
    "        mirmachine_after_filters.at[index, 'star_length'] = star_length\n",
    "        mirmachine_after_filters.at[index, 'hairpin_folding'] = fold\n",
    "        mirmachine_after_filters.at[index, 'mature_start'] = int(mature_start)+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0edd9dd0-3560-4aa7-a2d9-b5af56222ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66967/576005874.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['mature_start'] = df['mature_start'].astype('Int64')\n"
     ]
    }
   ],
   "source": [
    "def update_mature_sequences(df):\n",
    "    # Make sure 'mature_start' is of integer type for comparison where it's not NaN\n",
    "    df['mature_start'] = df['mature_start'].astype('Int64')  \n",
    "    \n",
    "    # Define a function to apply to each row\n",
    "    def update_row(row):\n",
    "        if pd.notna(row['mature_start']) and row['mature_start'] > 30:\n",
    "            new_mature = row['hairpin_trimmed'][row['mature_start']-1:]\n",
    "            row['mature'] = new_mature\n",
    "            row['mature_len'] = len(new_mature)\n",
    "        return row\n",
    "    \n",
    "    # Apply the function across the DataFrame row-wise\n",
    "    df = df.apply(update_row, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "mirmachine_after_filters = update_mature_sequences(mirmachine_after_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a67c9028-5c75-4b13-9407-e7c33438efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirmachine_after_filters.to_csv('./Data_output/gff_output/bastian_data_after_filters_with_star_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cbccad2-d94c-4e72-b90e-b80576b62581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    116776.000000\n",
       " mean         22.163767\n",
       " std           2.287793\n",
       " min           4.000000\n",
       " 25%          21.000000\n",
       " 50%          22.000000\n",
       " 75%          23.000000\n",
       " max          59.000000\n",
       " Name: star_length, dtype: float64,\n",
       " count    116776.000000\n",
       " mean         22.226493\n",
       " std           0.557070\n",
       " min          22.000000\n",
       " 25%          22.000000\n",
       " 50%          22.000000\n",
       " 75%          22.000000\n",
       " max          34.000000\n",
       " Name: mature_len, dtype: float64,\n",
       " count    116776.000000\n",
       " mean         15.749726\n",
       " std           3.027747\n",
       " min           0.000000\n",
       " 25%          14.000000\n",
       " 50%          16.000000\n",
       " 75%          18.000000\n",
       " max          34.000000\n",
       " Name: loop_length, dtype: float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_loop_length(row):\n",
    "    # Assuming the mature sequence comes after the star sequence\n",
    "    # This will need adjustment if the assumption doesn't always hold\n",
    "    if row['star_start'] < row['mature_start']:  # Star comes first\n",
    "        loop_start = row['star_start'] + row['star_length']\n",
    "        loop_end = row['mature_start'] - 1\n",
    "    else:  # Mature comes first\n",
    "        loop_start = row['mature_start'] + row['mature_len']\n",
    "        loop_end = row['star_start'] - 1\n",
    "    return max(0, loop_end - loop_start + 1)\n",
    "\n",
    "# Add loop length to the dataframe\n",
    "mirmachine_after_filters['loop_length'] = mirmachine_after_filters.apply(calculate_loop_length, axis=1)\n",
    "\n",
    "# Statistics for star, mature, and loop lengths\n",
    "star_stats = mirmachine_after_filters['star_length'].describe()\n",
    "mature_stats = mirmachine_after_filters['mature_len'].describe()\n",
    "loop_stats = mirmachine_after_filters['loop_length'].describe()\n",
    "\n",
    "star_stats, mature_stats, loop_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ed7ef6a-93a0-463f-832f-d393f83dc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(df, star_length_threshold=(22,25), mature_length_threshold=(22,23), loop_length_threshold=(8,25)):\n",
    "    # Filter based on the given thresholds\n",
    "    filtered_df = df[\n",
    "        (df['star_length'] >= star_length_threshold[0]) & (df['star_length'] <= star_length_threshold[1]) &\n",
    "        (df['mature_len'] >= mature_length_threshold[0]) & (df['mature_len'] <= mature_length_threshold[1]) &\n",
    "        (df['loop_length'] >= loop_length_threshold[0]) & (df['loop_length'] <= loop_length_threshold[1])\n",
    "    ]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example of using the filter function with arbitrary thresholds\n",
    "# These thresholds should be adjusted based on the specific criteria you're interested in\n",
    "mirmachine_after_filters_with_star = filter_dataset(mirmachine_after_filters)\n",
    "\n",
    "# Display the shape of the filtered dataframe to see how many rows it contains after filtering\n",
    "mirmachine_after_filters_with_star.shape\n",
    "\n",
    "mirmachine_after_filters_with_star.to_csv('./Data_output/gff_output/bastian_data_after_filters_with_star_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e2721-1f31-49b7-ac95-8740db82926a",
   "metadata": {},
   "source": [
    "### Extract Biolgical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370ef2de-9b6c-4b93-830c-f427bba7fb56",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ct_data(sequence, structure, output_file):\n",
    "    ct_data = {}\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(f\"{len(sequence)} ENERGY\\n\")\n",
    "        stack = []\n",
    "        \n",
    "        for i, (nt, struct) in enumerate(zip(sequence, structure), start=1):\n",
    "            prev_nt = i - 1 if i != 1 else 0\n",
    "            next_nt = i + 1 if i != len(sequence) else 0\n",
    "            \n",
    "            if struct == '(':\n",
    "                stack.append(i)\n",
    "                ct_data[i] = [i, nt, prev_nt, next_nt, 0, i]  # Temporarily set as unpaired\n",
    "            elif struct == ')':\n",
    "                partner = stack.pop()\n",
    "                f.write(f\"{i} {nt} {prev_nt} {next_nt} {partner} {i}\\n\")\n",
    "                ct_data[i] = [i, nt, prev_nt, next_nt, partner, i]\n",
    "                ct_data[partner][4] = i  # Update partner's pairing information\n",
    "            else:\n",
    "                f.write(f\"{i} {nt} {prev_nt} {next_nt} 0 {i}\\n\")\n",
    "                ct_data[i] = [i, nt, prev_nt, next_nt, 0, i]\n",
    "\n",
    "    return ct_data\n",
    "\n",
    "def dotbracket_to_ct(sequence, structure):\n",
    "    # Initialize the list for CT data\n",
    "    ct_data = []\n",
    "    \n",
    "    # Get the pair table from the dot-bracket structure\n",
    "    # The pair table is 1-indexed and the first element is the length of the RNA\n",
    "    pair_table = RNA.ptable(structure)\n",
    "    \n",
    "    # Loop through each nucleotide in the sequence\n",
    "    for i, nt in enumerate(sequence, start=1):\n",
    "        # Get the pairing partner from the pair table\n",
    "        partner = pair_table[i]\n",
    "        \n",
    "        # Write the CT data: index, nt, prev, next, partner, index\n",
    "        prev_nt = i - 1 if i > 1 else 0\n",
    "        next_nt = i + 1 if i < len(sequence) else 0\n",
    "        \n",
    "        # Append the data as a tuple or a list\n",
    "        ct_data.append((i, nt, prev_nt, next_nt, partner, i))\n",
    "    \n",
    "    return ct_data\n",
    "\n",
    "                \n",
    "def decode_structure(encoded_seq):\n",
    "    # Reverse the translation_dict to map encoded chars back to their original pairs\n",
    "    reverse_translation_struct = {v: k[0] for k, v in translation_dict.items()}\n",
    "\n",
    "    decoded_structure = ''\n",
    "\n",
    "    i = 0\n",
    "    while i < len(encoded_seq):\n",
    "        # Check for special tokens and treat them separately\n",
    "        if encoded_seq[i:i+5] in {'ZZZZZ', 'BBBBB', 'DDDDD', 'FFFFF'}:\n",
    "            decoded_structure += encoded_seq[i:i+5]\n",
    "            i += 5\n",
    "        elif encoded_seq[i] in reverse_translation_struct:\n",
    "            decoded_structure += reverse_translation_struct[encoded_seq[i]]\n",
    "            i += 1\n",
    "        else:\n",
    "            decoded_structure += '.'\n",
    "            i += 1\n",
    "\n",
    "    return decoded_structure\n",
    "\n",
    "def calculate_global_alignment(sequence1, sequence2):\n",
    "    alignments = pairwise2.align.globalxx(sequence1, sequence2)\n",
    "    return alignments[0][2]\n",
    "\n",
    "\n",
    "def calculate_novelty_global(sequences, training_set):\n",
    "    total_score = 0\n",
    "    for generated in tqdm(sequences):\n",
    "        # Calculate the average global alignment score of a generated sequence to all sequences in the training set\n",
    "        scores = [calculate_global_alignment(generated, train_seq) for train_seq in training_set]\n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        total_score += avg_score\n",
    "    return total_score / len(sequences)\n",
    "\n",
    "def calculate_local_diversity(gen_seq, real_sequences):\n",
    "    local_scores = [(pairwise2.align.localxx(gen_seq, real_seq, score_only=True), real_seq) for real_seq in real_sequences]\n",
    "    max_score, max_real_seq = max(local_scores, key=lambda x: x[0])\n",
    "    normalized_max_score = max_score / min(len(gen_seq), len(max_real_seq))\n",
    "    avg_score = sum(score for score, _ in local_scores) / len(real_sequences)\n",
    "    return (round(avg_score, 2), round(normalized_max_score, 2), max_real_seq)\n",
    "\n",
    "def calculate_global_diversity(gen_seq, real_sequences):\n",
    "    global_scores = [(pairwise2.align.globalxx(gen_seq, real_seq, score_only=True), real_seq) for real_seq in real_sequences]\n",
    "    max_score, max_real_seq = max(global_scores, key=lambda x: x[0])\n",
    "    normalized_max_score = max_score / min(len(gen_seq), len(max_real_seq))\n",
    "    avg_score = sum(score for score, _ in global_scores) / len(real_sequences)\n",
    "    return (round(avg_score, 2), round(normalized_max_score, 2), max_real_seq)\n",
    "\n",
    "# Helper function to count connections (in mature or star)\n",
    "def count_connections(start, end, ct_data):\n",
    "    connections = 0\n",
    "    for i in range(start, end + 1):\n",
    "        if ct_data[i][4] != 0 and not (start <= ct_data[i][4] <= end):\n",
    "            connections += 1\n",
    "    return connections\n",
    "\n",
    "def calculate_max_bulge(mature_range, star_range, ct_data):\n",
    "    max_bulge_mature = 0\n",
    "    max_bulge_star = 0\n",
    "    current_bulge = 0\n",
    "    in_bulge = False\n",
    "    bulge_start = -1\n",
    "    bulge_end = -1\n",
    "    mature_bulges = []\n",
    "    star_bulges = []\n",
    "\n",
    "    for i in range(1, len(ct_data)):\n",
    "        if ct_data[i][4] == 0:  # If current position is unpaired\n",
    "            if not in_bulge:\n",
    "                bulge_start = i-1  # Start of the bulge\n",
    "                # print(i,bulge_start)\n",
    "                in_bulge = True\n",
    "            current_bulge += 1\n",
    "            # print(ct_data[i+1] , ct_data[i+1][4])\n",
    "            if i == len(ct_data)-1 or ct_data[i+1][4] != 0:  # If it's the last position or next is paired\n",
    "                bulge_end = i+1  # End of the bulge\n",
    "                # print(i,bulge_end)\n",
    "                # Check if the bulge is completely contained within the mature range\n",
    "                if bulge_start >= mature_range[0] and bulge_end <= mature_range[1]:\n",
    "                    # print(f\"Mature Bulge found from index {bulge_start} to {bulge_end}. Size: {current_bulge}\")\n",
    "                    mature_bulges.append((bulge_start, bulge_end))\n",
    "                    max_bulge_mature = max(max_bulge_mature, current_bulge)\n",
    "                # Check if the bulge is completely contained within the star range\n",
    "                elif bulge_start >= star_range[0] and bulge_end <= star_range[1]:\n",
    "                    # print(f\"Star Bulge found from index {bulge_start} to {bulge_end}. Size: {current_bulge}\")\n",
    "                    star_bulges.append((bulge_start, bulge_end))\n",
    "                    max_bulge_star = max(max_bulge_star, current_bulge)\n",
    "                current_bulge = 0\n",
    "                in_bulge = False\n",
    "        else:\n",
    "            current_bulge = 0\n",
    "            in_bulge = False\n",
    "\n",
    "    return {\n",
    "        \"mature_max_bulge\": max_bulge_mature,\n",
    "        \"star_max_bulge\": max_bulge_star,\n",
    "        \"mature_bulges\": mature_bulges,\n",
    "        \"star_bulges\": star_bulges\n",
    "    }\n",
    "\n",
    "\n",
    "def debug_print(debug, *args):\n",
    "    if debug:\n",
    "        print(*args)\n",
    "\n",
    "def check_seed_family(seed):\n",
    "    # Load seed families from CSV\n",
    "\n",
    "    filename = os.path.abspath(\"/sise/vaksler-group/IsanaRNA/Transformers/Rom/Data_source/seed_family_from_mirgendb.csv\")\n",
    "\n",
    "    # Read CSV using pandas\n",
    "    df = pd.read_csv(filename, encoding='ISO-8859-1')\n",
    "\n",
    "    # Create a dictionary from the 'Seed' and 'Family' columns\n",
    "    seed_family_dict = df.set_index('Seed')['Family'].to_dict()\n",
    "    \n",
    "    return seed_family_dict.get(seed, \"Unknown\")\n",
    "\n",
    "# Helper function to calculate UG & UGUG\n",
    "def find_ug_sequences(decoded_seq, mature_start, mature_end, threshold=3):\n",
    "    # Calculate the search ranges considering the threshold\n",
    "    ug_search_start = max(mature_end - 14 - threshold, 0)\n",
    "    ug_search_end = min(mature_start + threshold, len(decoded_seq))\n",
    "    \n",
    "    ugug_search_start = max(mature_end + 1 - threshold, 0)\n",
    "    ugug_search_end = min(mature_end + 3 + threshold, len(decoded_seq))\n",
    "    \n",
    "    # Search for 'UG' and 'UGUG' sequences in the calculated ranges\n",
    "    ug_index = decoded_seq.find('UG', ug_search_start, ug_search_end) + 1  # +1 to make it 1-indexed\n",
    "    ug = ug_index if ug_index != 0 else \"FALSE\"\n",
    "    \n",
    "    ugug_index = decoded_seq.find('UGUG', ugug_search_start, ugug_search_end) + 1  # +1 to make it 1-indexed\n",
    "    ugug = ugug_index if ugug_index != 0 else \"FALSE\"\n",
    "    \n",
    "    return ug, ugug\n",
    "\n",
    "# Helper function to mer features (for sizes 1 or 2)\n",
    "def calculate_mer_ratios(sequence, mer_size):\n",
    "    total_length = len(sequence)\n",
    "    # If mer_size is greater than the sequence length, return an error or handle appropriately\n",
    "    if mer_size > total_length:\n",
    "        return \"(0.00 .. 0.00)\"\n",
    "    \n",
    "    # Generate all possible combinations of nucleotides of length mer_size\n",
    "    possible_mers = [''.join(p) for p in itertools.product('AUCG', repeat=mer_size)]\n",
    "    mer_counts = Counter([sequence[i:i+mer_size] for i in range(total_length - mer_size + 1)])\n",
    "    \n",
    "    # Calculate ratios\n",
    "    mer_ratios = {mer: mer_counts[mer] / total_length for mer in possible_mers}\n",
    "    max_ratio = max(mer_ratios.values(), default=0)\n",
    "    min_ratio = min(mer_ratios.values(), default=0)\n",
    "    \n",
    "    return f\"({min_ratio:.2f} .. {max_ratio:.2f})\"\n",
    "\n",
    "def calculate_energy(sequence):\n",
    "    # Calculate the secondary structure and the free energy of the structure\n",
    "    structure, energy = RNA.fold(sequence)\n",
    "    \n",
    "    return energy\n",
    "\n",
    "def is_valid_dot_bracket(structure, sequence):\n",
    "    stack = []\n",
    "    valid_pairs = [('U', 'G'), ('G', 'U'), ('C', 'G'), ('G', 'C'), ('A', 'U'), ('U', 'A')]\n",
    "    invalid_pairs_dict = {}\n",
    "    \n",
    "    for i, char in enumerate(structure):\n",
    "        if char == '(':\n",
    "            stack.append((i, sequence[i]))\n",
    "        elif char == ')':\n",
    "            if not stack:\n",
    "                return False, invalid_pairs_dict\n",
    "            else:\n",
    "                position, nucleotide = stack.pop()\n",
    "                if (nucleotide, sequence[i]) not in valid_pairs:\n",
    "                    invalid_pair = f\"{nucleotide}{sequence[i]}\"\n",
    "                    invalid_pairs_dict[invalid_pair] = invalid_pairs_dict.get(invalid_pair, 0) + 1\n",
    "                    \n",
    "    # Check if there are any unmatched parentheses left\n",
    "    if stack:\n",
    "        return False, invalid_pairs_dict\n",
    "    \n",
    "    # Check if any invalid pairs were found\n",
    "    if invalid_pairs_dict:\n",
    "        return False, invalid_pairs_dict\n",
    "        \n",
    "    return True, invalid_pairs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66af0f96-689f-4101-af99-96ef1cc83a4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_index(index):\n",
    "    return index + 1\n",
    "\n",
    "\n",
    "def extract_features_only_nts(decoded_seq, full_seq_folding, mature, star):\n",
    "    # Save CT file\n",
    "    if is_valid_dot_bracket(full_seq_folding,decoded_seq):\n",
    "        ct_data = get_ct_data(decoded_seq, full_seq_folding, \"output.ct\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Locate mature and star sequences within the full sequence\n",
    "    mature_start = decoded_seq.find(mature)\n",
    "    mature_end = mature_start + len(mature) - 1  # Adjust to 0-based indexing\n",
    "    star_start = decoded_seq.find(star)\n",
    "    star_end = star_start + len(star) - 1  # Adjust to 0-based indexing\n",
    "    if mature_start < 0 or star_start < 0:\n",
    "        print('mature ot start invalid')\n",
    "        return None\n",
    "\n",
    "    if mature_start < star_start:\n",
    "        loop = decoded_seq[mature_end+1:star_start]\n",
    "        flank1 = decoded_seq[:mature_start]\n",
    "        flank2 = decoded_seq[star_end+1:]\n",
    "        direction = '5p'\n",
    "    else:\n",
    "        loop = decoded_seq[star_end+1:mature_start]\n",
    "        flank1 = decoded_seq[:star_start]\n",
    "        flank2 = decoded_seq[mature_end+1:]\n",
    "        direction = '3p'\n",
    "\n",
    "    # Compute the seed section\n",
    "    seed_start = mature_start + 2  # 2nd nucleotide, 0-indexed\n",
    "    seed_end = seed_start + 7  # 7th nucleotide, 0-indexed\n",
    "    seed = decoded_seq[seed_start-1:seed_end-1]  \n",
    "    seed_family = check_seed_family(seed) # loading dict from shared folder \n",
    "\n",
    "    # Calculate the indices for Loop, flank1, and flank2\n",
    "    loop_start_index = decoded_seq.find(loop) + 1\n",
    "    loop_end_index = loop_start_index + len(loop) - 1\n",
    "\n",
    "    flank1_start_index = decoded_seq.find(flank1) + 1\n",
    "    flank1_end_index = flank1_start_index + len(flank1) - 1\n",
    "\n",
    "    flank2_start_index = decoded_seq.find(flank2) + 1\n",
    "    flank2_end_index = flank2_start_index + len(flank2) - 1\n",
    "    \n",
    "    mature_range, star_range = (adjust_index(mature_start), adjust_index(mature_end)), (adjust_index(star_start), adjust_index(star_end))\n",
    "    \n",
    "    # Feature calculations\n",
    "    # print(mature_start, mature_end , len(ct_data))\n",
    "    mature_connections = count_connections(adjust_index(mature_start), adjust_index(mature_end), ct_data)\n",
    "    mature_bp_ratio = mature_connections / len(mature) if len(mature) != 0 else 0\n",
    "    calculate_max_bulge_result = calculate_max_bulge(mature_range, star_range, ct_data)\n",
    "    mature_max_bulge, star_max_bulge = calculate_max_bulge_result[\"mature_max_bulge\"], calculate_max_bulge_result[\"star_max_bulge\"]\n",
    "    mature_bulges = calculate_max_bulge_result[\"mature_bulges\"]\n",
    "    star_bulges = calculate_max_bulge_result[\"star_bulges\"]\n",
    "    # mature_max_asymmetry = calculate_bulge_asymmetry(mature_bulges, ct_data , 'mature')\n",
    "    # print('mature',mature_bulges)\n",
    "    # star_max_asymmetry = calculate_bulge_asymmetry(star_bulges, ct_data,'star')\n",
    "    # print('star',star_bulges)\n",
    "    star_connections = count_connections(adjust_index(star_start), adjust_index(star_end), ct_data)\n",
    "    star_bp_ratio = star_connections / len(star) if len(star) != 0 else 0\n",
    "    ug, ugug = find_ug_sequences(decoded_seq, mature_start, mature_end, threshold=10)\n",
    "    hairpin_trimmed = decoded_seq.replace(flank1, '').replace(flank2,'')\n",
    "    h_start = adjust_index(decoded_seq.find(hairpin_trimmed))\n",
    "    h_end = mature_start + len(hairpin_trimmed)\n",
    "    energy = calculate_energy(hairpin_trimmed)\n",
    "    one_mer_mature = calculate_mer_ratios(mature, 1)\n",
    "    two_mer_mature = calculate_mer_ratios(mature, 2)\n",
    "    one_mer_h_trimm = calculate_mer_ratios(hairpin_trimmed, 1)\n",
    "    two_mer_h_trimm = calculate_mer_ratios(hairpin_trimmed, 2)\n",
    "    one_mer_full = calculate_mer_ratios(decoded_seq, 1)\n",
    "    two_mer_full = calculate_mer_ratios(decoded_seq, 2)\n",
    "    # ct_data2 = dotbracket_to_ct(decoded_seq, full_seq_folding)\n",
    "\n",
    "\n",
    "    feature_dict = {\n",
    "        'full_seq': decoded_seq,\n",
    "        'Mature': mature,\n",
    "        'Mature_Length': len(mature),\n",
    "        'Star': star,\n",
    "        'End_star': adjust_index(star_end),\n",
    "        'full_seq_folding': full_seq_folding,\n",
    "        'Loop_seq': loop,\n",
    "        'Loop_length': len(loop),\n",
    "        'flank1': flank1,\n",
    "        'flank2': flank2,\n",
    "        'Mature_start': adjust_index(mature_start),\n",
    "        'Mature_end': adjust_index(mature_end),\n",
    "        'Star_start': adjust_index(star_start),\n",
    "        'Star_end': adjust_index(star_end),\n",
    "        'Star_length': len(star),\n",
    "        'Mature_length': len(mature),\n",
    "        'Loop_seq_start': loop_start_index,\n",
    "        'Loop_seq_end': loop_end_index,\n",
    "        'flank1_start': flank1_start_index,\n",
    "        'flank1_end': flank1_end_index,\n",
    "        'flank2_start': flank2_start_index,\n",
    "        'flank2_end': flank2_end_index,\n",
    "        'seed': seed,\n",
    "        'seed_start': seed_start,\n",
    "        'seed_end': seed_end,\n",
    "        'seed_family': seed_family,\n",
    "        '3p/5p': direction,\n",
    "        'Mature_connections': mature_connections,\n",
    "        'Mature_BP_ratio': round(mature_bp_ratio, 2),\n",
    "        'Mature_max_bulge': mature_max_bulge,\n",
    "        'Star_connections': star_connections,\n",
    "        'Star_BP_ratio': round(star_bp_ratio, 2),\n",
    "        'Star_max_bulge': star_max_bulge,\n",
    "        'UG': ug,\n",
    "        'UGUG': ugug,\n",
    "        'hairpin_trimmed': hairpin_trimmed,\n",
    "        'hairpin_trimmed_length': len(hairpin_trimmed),\n",
    "        'folding_energy': round(energy, 2),\n",
    "        'one_mer_mature': one_mer_mature,\n",
    "        'two_mer_mature': two_mer_mature,\n",
    "        'one_mer_hairpin_trimmed': one_mer_h_trimm ,\n",
    "        'two_mer_hairpin_trimmed': two_mer_h_trimm ,\n",
    "        'one_mer_full': one_mer_full,\n",
    "        'two_mer_full': two_mer_full,\n",
    "\n",
    "    }\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faf211ff-0333-4b49-9d06-0b59372679ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running RNAfold: 100%|██████████| 116776/116776 [22:24<00:00, 86.84it/s]\n"
     ]
    }
   ],
   "source": [
    "def run_rnafold(rna_sequence):\n",
    "    fold, energy = RNA.fold(rna_sequence)\n",
    "    return fold\n",
    "\n",
    "mirmachine_after_filters_with_star['full_seq_folding'] = [run_rnafold(x) for x in tqdm(mirmachine_after_filters['full_seq'].tolist(), desc=\"Running RNAfold\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d2ee5b3-6692-4607-b265-1a02c9c5aaaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 125/116776 [00:08<2:10:25, 14.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mirmachine_after_filters_renamed \u001b[38;5;241m=\u001b[39m mirmachine_after_filters\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstar\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStar\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m----> 2\u001b[0m mirmachine_with_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_from_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmirmachine_after_filters_renamed\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mextract_features_from_df\u001b[0;34m(rna_df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Add tqdm around your loop\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(rna_df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(rna_df), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting features\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Ensure to capture the index to align later\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_only_nts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_seq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_seq_folding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Include the original index in your feature to align during concat\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         feature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n",
      "Cell \u001b[0;32mIn[14], line 36\u001b[0m, in \u001b[0;36mextract_features_only_nts\u001b[0;34m(decoded_seq, full_seq_folding, mature, star)\u001b[0m\n\u001b[1;32m     34\u001b[0m seed_end \u001b[38;5;241m=\u001b[39m seed_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m7\u001b[39m  \u001b[38;5;66;03m# 7th nucleotide, 0-indexed\u001b[39;00m\n\u001b[1;32m     35\u001b[0m seed \u001b[38;5;241m=\u001b[39m decoded_seq[seed_start\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:seed_end\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \n\u001b[0;32m---> 36\u001b[0m seed_family \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_seed_family\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# loading dict from shared folder \u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate the indices for Loop, flank1, and flank2\u001b[39;00m\n\u001b[1;32m     39\u001b[0m loop_start_index \u001b[38;5;241m=\u001b[39m decoded_seq\u001b[38;5;241m.\u001b[39mfind(loop) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[13], line 160\u001b[0m, in \u001b[0;36mcheck_seed_family\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    157\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/sise/vaksler-group/IsanaRNA/Transformers/Rom/Data_source/seed_family_from_mirgendb.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Read CSV using pandas\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mISO-8859-1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Create a dictionary from the 'Seed' and 'Family' columns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m seed_family_dict \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeed\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFamily\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1049\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1332\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mirmachine_after_filters_renamed = mirmachine_after_filters.rename(columns={\"mature\": \"Mature\", \"star\": \"Star\"})\n",
    "mirmachine_with_features = extract_features_from_df(mirmachine_after_filters_renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed5aa20f-8249-411a-9e1b-7aeeefad1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mTGGTTTTCATAATGATTTGAC\u001b[0mAGATTGTTTGATATTC\u001b[91mTGAGATCATTGTGAAAGCTGAT\u001b[0m\n",
      "\u001b[91mACGTATACTGAATGTATCCTGA\u001b[0mGTGCATCATTCTTTCC\u001b[94mGGTATACCTTCAGTATACGTAA\u001b[0m\n",
      "\u001b[94mCCGTGCTTCCTTACTTCCC\u001b[0mATAGTGCTTATGATCGTA\u001b[91mTGGAATGTAAAGAAGTATGGAG\u001b[0m\n",
      "\u001b[94mAGTGGAGGTGTGATCTCTTC\u001b[0mACTTTTTTCTATTAAAG\u001b[91mTGAGATTCAACTCCTCCAACTT\u001b[0mA\n",
      "\u001b[94mAGCTGGTTGACTTCGGGTCA\u001b[0mAATTGTAATTCGAATATCAT\u001b[91mTTGGTCCCCTTCAACCAGCTGT\u001b[0m\n",
      "\u001b[94mACGCGTATTCTTGGGGAATTA\u001b[0mACACACATTACGAGCTG\u001b[91mTTATTGCTTGAGAATACACGTA\u001b[0mG\n",
      "\u001b[94mCCTTGTCATTCTTCTT\u001b[0mGCCCCGTGTATTGATACGAC\u001b[91mTGGACGGAGAACTGATAAGGGC\u001b[0m\n",
      "\u001b[91mAGATATGTTTGATATTCTTGGT\u001b[0mTGTTTCGTTCTGTATCACCCGG\u001b[94mGAATCAAACATATTACC\u001b[0m\n",
      "\u001b[94mCCATCGAAGTTGGTTTGTCAT\u001b[0mAGATCCATTAGTAAC\u001b[91mTATCACAGCCAGCTTTGATGAG\u001b[0mC\n",
      "\u001b[94mCTGTCAAAGCGGCGGTGAA\u001b[0mATGTCTACTGCGTTCA\u001b[91mTATCACAGCCACTTTGATGTGG\u001b[0mT\n",
      "\u001b[94mTCGTAAAAATGGTTGTGCC\u001b[0mATGTTGGTTATGATTCA\u001b[91mTATCACAGCCATTTTTGACGAG\u001b[0mT\n",
      "\u001b[94mTCACAAAGTGGTTGTGATTTGC\u001b[0mATGTTCTGAGACA\u001b[91mTATCACAGCCAGCTTTGATGAG\u001b[0mC\n",
      "\u001b[94mCCGACAAAGCGGCCGTGAA\u001b[0mATGGTCACTACACACA\u001b[91mTATCACAGCCAGCTTTGTTGAC\u001b[0mT\n",
      "\u001b[91mTTGTGACCGTCACTAACGGGCA\u001b[0mGTGGATAATAAATTTTGC\u001b[94mTCGTTTTGATGATCGCAAAA\u001b[0m\n",
      "\u001b[94mAGCTGCTGGACACTGCATA\u001b[0mAGATTAGTGACAGCTGTACTC\u001b[91mTTGTGCGTGTGACAGCGGCTAT\u001b[0m\n",
      "\u001b[94mAACTATTGGTCACTGCACA\u001b[0mGGACTAGTGACGTTATTATACTC\u001b[91mTTGTGCGTGTTCCAATAGTTAT\u001b[0m\n",
      "\u001b[91mAAATATCAGCTGGTAATTCTGG\u001b[0mGGTTTCGACACCCA\u001b[94mGGCTACCGGTTGATATAAAG\u001b[0m\n",
      "C\u001b[91mTAAGTACTAGTGCCGCAGGAGT\u001b[0mGGTAGTTCCCATG\u001b[94mTCTCCTGCTGCCTAAGTGCTTATCA\u001b[0m\n",
      "\u001b[94mCGCGCTACTCTGGCGCCAGG\u001b[0mACTGTCTTCACGAG\u001b[91mTCAGGTACCTGAAGTAGCGCGC\u001b[0mG\n",
      "\u001b[94mAGCGAGGTATAGAGTTCCT\u001b[0mACGTATAAAGCAGCTG\u001b[91mTAGGAACTTCATACCGTGCTCT\u001b[0m\n",
      "\u001b[94mCCGGACGAACTTCCCAGTTCG\u001b[0mGCCGGCATTATCAATGG\u001b[91mTCGGTGGGATCTTCGTCCGTTT\u001b[0m\n",
      "\u001b[94mGATGAGTGGAGGTTTAGTGC\u001b[0mATGTTATTTGTAACTCA\u001b[91mTGACTAGATCCACACTCATCCA\u001b[0m\n",
      "\u001b[94mGATGAGTGACTCTCTAGTGC\u001b[0mAAGTCGTATCGCCTGTATCT\u001b[91mTGACTAGATTTTCACTTATCGC\u001b[0m\n",
      "\u001b[94mGATGGGTATAAGTCTAGTATC\u001b[0mACAGATTTATTGTTG\u001b[91mTGACTAGATCTACACTCATTGA\u001b[0m\n",
      "\u001b[94mGGCGAGTTTGTTTCTGGTATC\u001b[0mATGTTGCATTTATCCA\u001b[91mTGACTAGATCCATACTCGTCTG\u001b[0m\n",
      "\u001b[91mAAGAGAGCTATCCGTCGACAGT\u001b[0mATTGATATTAAACACT\u001b[94mGTCATGGAGTTGCTCTCTTTA\u001b[0m\n",
      "\u001b[91mTAGCCTCTCCTTGGCTTTGTCT\u001b[0mGTGTGTTCAGAACGTTTCAGA\u001b[94mCATAGCCTGATAGAGGTTACG\u001b[0m\n",
      "\u001b[94mACTGTATTCGAGTGTGTGGAT\u001b[0mAGAGTGCTCTAATTCTC\u001b[91mTAGCACCATTCGAATTCAGTGC\u001b[0m\n",
      "\u001b[91mATTGTACTTCATCAGGTGCTCT\u001b[0mGGTGATGATCGTTCCAGG\u001b[94mCGCTTGTTGGAGTACACTTA\u001b[0m\n",
      "\u001b[91mAGGCAAGATGTCGGCATAGCTG\u001b[0mATTGGCTTTGATATACGG\u001b[94mCTGTGTCACATCGAGCCAGC\u001b[0m\n",
      "\u001b[91mTGTCTTTTTCCGCTTTGCTGCT\u001b[0mGATTGCATTGTCGAACGTCAAC\u001b[94mAGCAAAGTGAAAAGGTCTCC\u001b[0m\n",
      "\u001b[94mCGGGTGCCACGCTGTGCTCT\u001b[0mCTCGGTAATAAGTGCGAG\u001b[91mTGAACACAGCTGGTGGTATCTC\u001b[0mAGT\n",
      "\u001b[91mTGGCAGTGTGGTTAGCTGGTTG\u001b[0mTTTAAGTTCTAAATACAACAG\u001b[94mCCTCTAACGACACTGCTCCT\u001b[0m\n",
      "\u001b[94mACCCGAGCGGTATGAGCAA\u001b[0mACTATACAATAACACTAG\u001b[91mTTTGTTCGCCCCGGCTCGTGTC\u001b[0mG\n",
      "\u001b[94mTCATTAGTTTAATGAACAA\u001b[0mAACTGCGGAAGT\u001b[91mTTTGTTCATTAAACTAATGAGa\u001b[0m\n",
      "\u001b[91mTGGAAGACTAGTGATTTTGTTG\u001b[0mTTTTATTGCATTCGTATAACAA\u001b[94mGAAATCACTAATCTCCTTA\u001b[0m\n",
      "\u001b[91mTGAAAGACATGGGTGGTGAGAT\u001b[0mGTCCCAGCACATCAAAATTCTC\u001b[94mACTACCTTGTCTTTCATG\u001b[0m\n",
      "\u001b[94mAGTTGGACAGGGGATCTT\u001b[0mGACAGTTCGTCCTGAAATGCTG\u001b[91mCCAGATCTATCTTTCCAGCTCA\u001b[0m\n",
      "\u001b[94mCGGGTTTCGAGGCGATGCA\u001b[0mACCGTGAAATATGTAATGG\u001b[91mTTCGTTGTCGACGAAACCTGCA\u001b[0m\n",
      "\u001b[94mCATCTTACCGGGCAGCATT\u001b[0mAGAGTCGTTCTGTTATTTTC\u001b[91mTAATACTGTCAGGTAAAGATGT\u001b[0mC\n"
     ]
    }
   ],
   "source": [
    "#verify results \n",
    "df = mirmachine_after_filters\n",
    "\n",
    "# ANSI color codes for printing in color\n",
    "RED = \"\\033[31m\"\n",
    "BLUE = \"\\033[34m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "def color_sequences(hairpin, mature, star):\n",
    "    \"\"\"\n",
    "    Colors the 'mature' substring in red and 'star' substring in blue within the 'hairpin' string.\n",
    "    \"\"\"\n",
    "    # ANSI escape codes for colors\n",
    "    RED = '\\033[91m'\n",
    "    BLUE = '\\033[94m'\n",
    "    END = '\\033[0m'  # Reset to default color\n",
    "\n",
    "    # Replace the 'mature' and 'star' sequences with colored versions\n",
    "    mature_colored = RED + mature + END\n",
    "    star_colored = BLUE + star + END\n",
    "\n",
    "    if mature in hairpin and star in hairpin:\n",
    "        # Find start indexes of 'mature' and 'star' in 'hairpin'\n",
    "        mature_start = hairpin.index(mature)\n",
    "        star_start = hairpin.index(star)\n",
    "\n",
    "        hairpin_colored = hairpin.replace(mature, mature_colored).replace(star, star_colored)\n",
    "\n",
    "    return hairpin_colored\n",
    "\n",
    "# Print the hairpin sequences with mature in red and star in blue\n",
    "for index, row in df.iterrows():\n",
    "    hairpin = row['hairpin_trimmed']\n",
    "    mature = row['mature']\n",
    "    star = row['star']\n",
    "\n",
    "    hairpin_colored = color_sequences(hairpin, mature, star)\n",
    "    print(hairpin_colored)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
